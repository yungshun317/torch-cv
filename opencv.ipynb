{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71b20d3-359f-4762-a5ac-f872999f7f0b",
   "metadata": {},
   "source": [
    "- **Graphical User Interface**\n",
    "- **Image Processing**\n",
    "- **Feature Detection & Description**\n",
    "- **Video Analysis**\n",
    "- **Camera Calibration & 3D Reconstruction**\n",
    "- **Machine Learning**\n",
    "- **Computational Photography**\n",
    "- **Object Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86d384-8c66-4e56-a2e5-296d301a3bb9",
   "metadata": {},
   "source": [
    "# 1. Graphical User Interface (GUI)\n",
    "## 1-1. Load, Display & Save Images\n",
    "1. `cv2.imread(filename, flags)`\n",
    "    - `flags`\n",
    "        - `cv2.IMREAD_COLOR`\n",
    "        - `cv2.IMREAD_UNCHANGED`\n",
    "        - `cv2.IMREAD_GRAYSCALE`\n",
    "\n",
    "[OpenCV Samples](https://github.com/opencv/opencv/tree/master/samples/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13fd89bd-3968-4ff1-b2f4-b34e26c571a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@347.096] global samples.cpp:61 findFile cv::samples::findFile('starry_night.jpg') => '/home/yungshun317/workspace/py/torch-cv/data/starry_night.jpg'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "cv2.samples.addSamplesDataSearchPath(\"/home/yungshun317/workspace/py/torch-cv/data/\")\n",
    "img = cv2.imread(cv2.samples.findFile(\"starry_night.jpg\"), cv2.IMREAD_UNCHANGED)\n",
    " \n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    " \n",
    "cv2.imshow(\"Display window\", img)\n",
    "k = cv2.waitKey(0)\n",
    " \n",
    "if k == ord(\"s\"):\n",
    "    cv2.imwrite(\"outputs/starry_night.png\", img)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162d985-42e7-44c6-83cf-e2a3b7eff5c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "955b391f-932a-4da7-8d55-b6057b2c997e",
   "metadata": {},
   "source": [
    "## 1-2. Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1d494f-8e6d-4497-afb5-33b60bfa9d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Line\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "# Create a black image\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    " \n",
    "# Draw a diagonal blue line with thickness of 5 px\n",
    "cv.line(img,(0,0),(511,511),(255,0,0),5)\n",
    "\n",
    "cv.imwrite(\"outputs/line.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e5421-de22-423c-a288-066e3cd8122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectangle\n",
    "cv.rectangle(img,(384,0),(510,128),(0,255,0),3)\n",
    "\n",
    "cv.imwrite(\"outputs/rectangle.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cd3c7-7f6f-4fe5-a884-b8d9c6f90d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circle\n",
    "cv.circle(img,(447,63), 63, (0,0,255), -1)\n",
    "\n",
    "cv.imwrite(\"outputs/circle.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962cdb2-5dc3-45a8-8969-9b44fc753fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ellipse\n",
    "cv.ellipse(img,(256,256),(100,50),0,0,180,255,-1)\n",
    "\n",
    "cv.imwrite(\"outputs/ellipse.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b6cc5-24bb-425b-bf8e-a4aca4e14a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polygon\n",
    "pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv.polylines(img,[pts],True,(0,255,255))\n",
    "\n",
    "cv.imwrite(\"outputs/polygon.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de9af4-1303-403a-a5d7-2a2c30816ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "cv.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,cv.LINE_AA)\n",
    "\n",
    "cv.imwrite(\"outputs/text.png\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc569a65-3fde-4e2d-b9f1-358a00264380",
   "metadata": {},
   "source": [
    "## 1-3. Paint Brush \n",
    "1. `setMouseCallback(winname, onMouse, userdata=0)`: Sets mouse handler for the specified window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ff7dbe-257e-4464-bef2-86b910ee4e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "events = [i for i in dir(cv) if 'EVENT' in i]\n",
    "print( events )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a6ad35-32fc-4841-aea1-dc8e4bd83dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    if event == cv.EVENT_LBUTTONDBLCLK:\n",
    "        cv.circle(img,(x,y),100,(255,0,0),-1)\n",
    " \n",
    "# Create a black image, a window and bind the function to window\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image',draw_circle)\n",
    "\n",
    "# Break when `ESC` is clicked\n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    if cv.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa07cf15-b2e4-4f60-b1af-799fa3584e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "ix,iy = -1,-1\n",
    " \n",
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global ix,iy,drawing,mode\n",
    " \n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    " \n",
    "    elif event == cv.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            if mode == True:\n",
    "                cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "            else:\n",
    "                cv.circle(img,(x,y),5,(0,0,255),-1)\n",
    " \n",
    "    elif event == cv.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode == True:\n",
    "            cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "        else:\n",
    "            cv.circle(img,(x,y),5,(0,0,255),-1)\n",
    "\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image',draw_circle)\n",
    " \n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    " \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033667f-50f6-47da-af8d-ad9b6933cd06",
   "metadata": {},
   "source": [
    "## 1-4. Color Palette\n",
    "1. `cv2.createTrackbar(trackbarname, winname, value, count, onChange=0, userdata=0)`: Creates a trackbar & attaches it to the specified window.\n",
    "2. `cv2.getTrackbarPos(trackbarname, winname)`: Returns the trackbar position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad3bef3-422e-451a-94e9-e267df18289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv.namedWindow('image')\n",
    " \n",
    "# create trackbars for color change\n",
    "cv.createTrackbar('R','image',0,255,nothing)\n",
    " \n",
    "cv.createTrackbar('G','image',0,255,nothing)\n",
    "cv.createTrackbar('B','image',0,255,nothing)\n",
    " \n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv.createTrackbar(switch, 'image',0,1,nothing)\n",
    " \n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    " \n",
    "    # get current positions of four trackbars\n",
    "    r = cv.getTrackbarPos('R','image')\n",
    "    g = cv.getTrackbarPos('G','image')\n",
    "    b = cv.getTrackbarPos('B','image')\n",
    "    s = cv.getTrackbarPos(switch,'image')\n",
    " \n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    " \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c47141-8a7a-4d21-ad35-8f6f767c8761",
   "metadata": {},
   "source": [
    "## 1-5. Capture Videos from Cameras\n",
    "1. `cv2.VideoCapture()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37664a1-b58c-43c3-901a-e6b59b06d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4385d-b74b-4c01-9924-b8a4ce7a5201",
   "metadata": {},
   "source": [
    "## 1-6. Play Videos from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0ba4e-72c6-45f0-be38-7ad40961b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture('data/vtest.avi')\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    " \n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a905fdd-e957-41c4-96d6-8dd9a6c9b5d1",
   "metadata": {},
   "source": [
    "## 1-7. Write Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b0482-9e3b-49df-b931-3f99f226e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    " \n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter('outputs/output.avi', fourcc, 20.0, (640,  480))\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    frame = cv.flip(frame, 0)\n",
    " \n",
    "    # write the flipped frame\n",
    "    out.write(frame)\n",
    " \n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0942a-f937-4d43-8a95-2658ed6fb552",
   "metadata": {},
   "source": [
    "# 2. Image Processing\n",
    "## 2-1. Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583ee34f-d036-41a4-89fa-ebf918036eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157 166 200]\n"
     ]
    }
   ],
   "source": [
    "# Access pixel values\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('data/messi5.jpg')\n",
    "px = img[100,100]\n",
    "print( px )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc0665e5-708f-4e70-8714-bc8d74451ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "blue = img[100,100,0]\n",
    "print( blue )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b629ca24-9824-4265-8d7f-4182653c1d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "# Modify pixel values\n",
    "img[100,100] = [255,255,255]\n",
    "print( img[100,100] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f923cc-ca43-4f52-b706-86f1fa66a5fa",
   "metadata": {},
   "source": [
    "## 2-2. Image Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a932e2c1-ab56-487d-a288-c227d3af82ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 548, 3)\n"
     ]
    }
   ],
   "source": [
    "# Image Properties\n",
    "print( img.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934d65f-e328-4030-b2e9-898249c2d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( img.size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b15d07-fba8-4e09-b3b3-7b2a0c3e90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( img.dtype )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c27ff-39f9-4dc1-9526-6d396a88c2ae",
   "metadata": {},
   "source": [
    "## 2-3. Region of Images (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45556f0d-5893-4b07-99d4-18b170745b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI\n",
    "ball = img[280:340, 330:390]\n",
    "img[273:333, 100:160] = ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03592b-dde1-40b3-b3e2-accdeb027371",
   "metadata": {},
   "source": [
    "## 2-4. Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9715f33-5702-4091-ad79-9f95f0979598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels\n",
    "b,g,r = cv.split(img)\n",
    "img = cv.merge((b,g,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6bd86b-21ea-40b2-bb89-cb830b48de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859774fc-257a-4ad8-b3b6-4f98dd7bd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:,:,2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622e681-be9e-497e-bf43-0a8908652b53",
   "metadata": {},
   "source": [
    "## 2-5. Borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0df8f-1d92-46bb-8843-e8616603b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borders\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "BLUE = [255,0,0]\n",
    " \n",
    "img1 = cv.imread('opencv-logo.png')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "replicate = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REPLICATE)\n",
    "reflect = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT)\n",
    "reflect101 = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT_101)\n",
    "wrap = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_WRAP)\n",
    "constant= cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_CONSTANT,value=BLUE)\n",
    " \n",
    "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
    "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
    "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
    "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
    "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
    "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745282f1-6620-4ba3-ac9e-4ba066c40bda",
   "metadata": {},
   "source": [
    "## 2-6. Arithmetic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf0d9a-e9c9-40e4-8b76-afddc6b9570e",
   "metadata": {},
   "source": [
    "### 2-6-1. Image Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2aa93-e93f-46b7-974f-c7a223b78d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.uint8([250])\n",
    "y = np.uint8([10])\n",
    " \n",
    "print( cv.add(x,y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6976c6-5b7e-48c6-85fb-b626510ebe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( x+y ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100a029-250c-4354-b0f8-3505c402f649",
   "metadata": {},
   "source": [
    "### 2-6-2. Image Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d7e96-f636-48e2-b089-138b05b58221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image blending\n",
    "img1 = cv.imread('ml.png')\n",
    "img2 = cv.imread('opencv-logo.png')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert img2 is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "dst = cv.addWeighted(img1,0.7,img2,0.3,0)\n",
    " \n",
    "cv.imshow('dst',dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e701f-17bf-41ce-8e20-20f6003df233",
   "metadata": {},
   "source": [
    "### 2-6-3. Bitwise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65da21d-2cbb-44a5-8850-3a4d9840ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitwise operations\n",
    "# Load two images\n",
    "img1 = cv.imread('messi5.jpg')\n",
    "img2 = cv.imread('opencv-logo-white.png')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert img2 is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# I want to put logo on top-left corner, So I create a ROI\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols]\n",
    " \n",
    "# Now create a mask of logo and create its inverse mask also\n",
    "img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(img2gray, 10, 255, cv.THRESH_BINARY)\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    " \n",
    "# Now black-out the area of logo in ROI\n",
    "img1_bg = cv.bitwise_and(roi,roi,mask = mask_inv)\n",
    " \n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv.bitwise_and(img2,img2,mask = mask)\n",
    " \n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv.add(img1_bg,img2_fg)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    " \n",
    "cv.imshow('res',img1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d58941-13f8-435a-842e-227e712ba968",
   "metadata": {},
   "source": [
    "## 2-7. Color Spaces\n",
    "1. `cv2.cvtColor(src, dst, code, dstCn=0, hint=cv2.ALGO_HINT_DEFAULT)`: Converts an image from one color space to another.\n",
    "    - `hint`\n",
    "        - `cv2.ALGO_HINT_DEFAULT`\n",
    "        - `cv2.ALGO_HINT_ACCURATE`\n",
    "        - `cv2.ALGO_HINT_APPROX`\n",
    "3. `cv2.inRange(src, lowerb, upperb, dst)`: Checks if array elements lie between the elements of 2 other arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc91e413-3070-46ca-9323-3b01babb794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COLOR_BAYER_BG2BGR', 'COLOR_BAYER_BG2BGRA', 'COLOR_BAYER_BG2BGR_EA', 'COLOR_BAYER_BG2BGR_VNG', 'COLOR_BAYER_BG2GRAY', 'COLOR_BAYER_BG2RGB', 'COLOR_BAYER_BG2RGBA', 'COLOR_BAYER_BG2RGB_EA', 'COLOR_BAYER_BG2RGB_VNG', 'COLOR_BAYER_BGGR2BGR', 'COLOR_BAYER_BGGR2BGRA', 'COLOR_BAYER_BGGR2BGR_EA', 'COLOR_BAYER_BGGR2BGR_VNG', 'COLOR_BAYER_BGGR2GRAY', 'COLOR_BAYER_BGGR2RGB', 'COLOR_BAYER_BGGR2RGBA', 'COLOR_BAYER_BGGR2RGB_EA', 'COLOR_BAYER_BGGR2RGB_VNG', 'COLOR_BAYER_GB2BGR', 'COLOR_BAYER_GB2BGRA', 'COLOR_BAYER_GB2BGR_EA', 'COLOR_BAYER_GB2BGR_VNG', 'COLOR_BAYER_GB2GRAY', 'COLOR_BAYER_GB2RGB', 'COLOR_BAYER_GB2RGBA', 'COLOR_BAYER_GB2RGB_EA', 'COLOR_BAYER_GB2RGB_VNG', 'COLOR_BAYER_GBRG2BGR', 'COLOR_BAYER_GBRG2BGRA', 'COLOR_BAYER_GBRG2BGR_EA', 'COLOR_BAYER_GBRG2BGR_VNG', 'COLOR_BAYER_GBRG2GRAY', 'COLOR_BAYER_GBRG2RGB', 'COLOR_BAYER_GBRG2RGBA', 'COLOR_BAYER_GBRG2RGB_EA', 'COLOR_BAYER_GBRG2RGB_VNG', 'COLOR_BAYER_GR2BGR', 'COLOR_BAYER_GR2BGRA', 'COLOR_BAYER_GR2BGR_EA', 'COLOR_BAYER_GR2BGR_VNG', 'COLOR_BAYER_GR2GRAY', 'COLOR_BAYER_GR2RGB', 'COLOR_BAYER_GR2RGBA', 'COLOR_BAYER_GR2RGB_EA', 'COLOR_BAYER_GR2RGB_VNG', 'COLOR_BAYER_GRBG2BGR', 'COLOR_BAYER_GRBG2BGRA', 'COLOR_BAYER_GRBG2BGR_EA', 'COLOR_BAYER_GRBG2BGR_VNG', 'COLOR_BAYER_GRBG2GRAY', 'COLOR_BAYER_GRBG2RGB', 'COLOR_BAYER_GRBG2RGBA', 'COLOR_BAYER_GRBG2RGB_EA', 'COLOR_BAYER_GRBG2RGB_VNG', 'COLOR_BAYER_RG2BGR', 'COLOR_BAYER_RG2BGRA', 'COLOR_BAYER_RG2BGR_EA', 'COLOR_BAYER_RG2BGR_VNG', 'COLOR_BAYER_RG2GRAY', 'COLOR_BAYER_RG2RGB', 'COLOR_BAYER_RG2RGBA', 'COLOR_BAYER_RG2RGB_EA', 'COLOR_BAYER_RG2RGB_VNG', 'COLOR_BAYER_RGGB2BGR', 'COLOR_BAYER_RGGB2BGRA', 'COLOR_BAYER_RGGB2BGR_EA', 'COLOR_BAYER_RGGB2BGR_VNG', 'COLOR_BAYER_RGGB2GRAY', 'COLOR_BAYER_RGGB2RGB', 'COLOR_BAYER_RGGB2RGBA', 'COLOR_BAYER_RGGB2RGB_EA', 'COLOR_BAYER_RGGB2RGB_VNG', 'COLOR_BGR2BGR555', 'COLOR_BGR2BGR565', 'COLOR_BGR2BGRA', 'COLOR_BGR2GRAY', 'COLOR_BGR2HLS', 'COLOR_BGR2HLS_FULL', 'COLOR_BGR2HSV', 'COLOR_BGR2HSV_FULL', 'COLOR_BGR2LAB', 'COLOR_BGR2LUV', 'COLOR_BGR2Lab', 'COLOR_BGR2Luv', 'COLOR_BGR2RGB', 'COLOR_BGR2RGBA', 'COLOR_BGR2XYZ', 'COLOR_BGR2YCR_CB', 'COLOR_BGR2YCrCb', 'COLOR_BGR2YUV', 'COLOR_BGR2YUV_I420', 'COLOR_BGR2YUV_IYUV', 'COLOR_BGR2YUV_UYNV', 'COLOR_BGR2YUV_UYVY', 'COLOR_BGR2YUV_Y422', 'COLOR_BGR2YUV_YUNV', 'COLOR_BGR2YUV_YUY2', 'COLOR_BGR2YUV_YUYV', 'COLOR_BGR2YUV_YV12', 'COLOR_BGR2YUV_YVYU', 'COLOR_BGR5552BGR', 'COLOR_BGR5552BGRA', 'COLOR_BGR5552GRAY', 'COLOR_BGR5552RGB', 'COLOR_BGR5552RGBA', 'COLOR_BGR5652BGR', 'COLOR_BGR5652BGRA', 'COLOR_BGR5652GRAY', 'COLOR_BGR5652RGB', 'COLOR_BGR5652RGBA', 'COLOR_BGRA2BGR', 'COLOR_BGRA2BGR555', 'COLOR_BGRA2BGR565', 'COLOR_BGRA2GRAY', 'COLOR_BGRA2RGB', 'COLOR_BGRA2RGBA', 'COLOR_BGRA2YUV_I420', 'COLOR_BGRA2YUV_IYUV', 'COLOR_BGRA2YUV_UYNV', 'COLOR_BGRA2YUV_UYVY', 'COLOR_BGRA2YUV_Y422', 'COLOR_BGRA2YUV_YUNV', 'COLOR_BGRA2YUV_YUY2', 'COLOR_BGRA2YUV_YUYV', 'COLOR_BGRA2YUV_YV12', 'COLOR_BGRA2YUV_YVYU', 'COLOR_BayerBG2BGR', 'COLOR_BayerBG2BGRA', 'COLOR_BayerBG2BGR_EA', 'COLOR_BayerBG2BGR_VNG', 'COLOR_BayerBG2GRAY', 'COLOR_BayerBG2RGB', 'COLOR_BayerBG2RGBA', 'COLOR_BayerBG2RGB_EA', 'COLOR_BayerBG2RGB_VNG', 'COLOR_BayerBGGR2BGR', 'COLOR_BayerBGGR2BGRA', 'COLOR_BayerBGGR2BGR_EA', 'COLOR_BayerBGGR2BGR_VNG', 'COLOR_BayerBGGR2GRAY', 'COLOR_BayerBGGR2RGB', 'COLOR_BayerBGGR2RGBA', 'COLOR_BayerBGGR2RGB_EA', 'COLOR_BayerBGGR2RGB_VNG', 'COLOR_BayerGB2BGR', 'COLOR_BayerGB2BGRA', 'COLOR_BayerGB2BGR_EA', 'COLOR_BayerGB2BGR_VNG', 'COLOR_BayerGB2GRAY', 'COLOR_BayerGB2RGB', 'COLOR_BayerGB2RGBA', 'COLOR_BayerGB2RGB_EA', 'COLOR_BayerGB2RGB_VNG', 'COLOR_BayerGBRG2BGR', 'COLOR_BayerGBRG2BGRA', 'COLOR_BayerGBRG2BGR_EA', 'COLOR_BayerGBRG2BGR_VNG', 'COLOR_BayerGBRG2GRAY', 'COLOR_BayerGBRG2RGB', 'COLOR_BayerGBRG2RGBA', 'COLOR_BayerGBRG2RGB_EA', 'COLOR_BayerGBRG2RGB_VNG', 'COLOR_BayerGR2BGR', 'COLOR_BayerGR2BGRA', 'COLOR_BayerGR2BGR_EA', 'COLOR_BayerGR2BGR_VNG', 'COLOR_BayerGR2GRAY', 'COLOR_BayerGR2RGB', 'COLOR_BayerGR2RGBA', 'COLOR_BayerGR2RGB_EA', 'COLOR_BayerGR2RGB_VNG', 'COLOR_BayerGRBG2BGR', 'COLOR_BayerGRBG2BGRA', 'COLOR_BayerGRBG2BGR_EA', 'COLOR_BayerGRBG2BGR_VNG', 'COLOR_BayerGRBG2GRAY', 'COLOR_BayerGRBG2RGB', 'COLOR_BayerGRBG2RGBA', 'COLOR_BayerGRBG2RGB_EA', 'COLOR_BayerGRBG2RGB_VNG', 'COLOR_BayerRG2BGR', 'COLOR_BayerRG2BGRA', 'COLOR_BayerRG2BGR_EA', 'COLOR_BayerRG2BGR_VNG', 'COLOR_BayerRG2GRAY', 'COLOR_BayerRG2RGB', 'COLOR_BayerRG2RGBA', 'COLOR_BayerRG2RGB_EA', 'COLOR_BayerRG2RGB_VNG', 'COLOR_BayerRGGB2BGR', 'COLOR_BayerRGGB2BGRA', 'COLOR_BayerRGGB2BGR_EA', 'COLOR_BayerRGGB2BGR_VNG', 'COLOR_BayerRGGB2GRAY', 'COLOR_BayerRGGB2RGB', 'COLOR_BayerRGGB2RGBA', 'COLOR_BayerRGGB2RGB_EA', 'COLOR_BayerRGGB2RGB_VNG', 'COLOR_COLORCVT_MAX', 'COLOR_GRAY2BGR', 'COLOR_GRAY2BGR555', 'COLOR_GRAY2BGR565', 'COLOR_GRAY2BGRA', 'COLOR_GRAY2RGB', 'COLOR_GRAY2RGBA', 'COLOR_HLS2BGR', 'COLOR_HLS2BGR_FULL', 'COLOR_HLS2RGB', 'COLOR_HLS2RGB_FULL', 'COLOR_HSV2BGR', 'COLOR_HSV2BGR_FULL', 'COLOR_HSV2RGB', 'COLOR_HSV2RGB_FULL', 'COLOR_LAB2BGR', 'COLOR_LAB2LBGR', 'COLOR_LAB2LRGB', 'COLOR_LAB2RGB', 'COLOR_LBGR2LAB', 'COLOR_LBGR2LUV', 'COLOR_LBGR2Lab', 'COLOR_LBGR2Luv', 'COLOR_LRGB2LAB', 'COLOR_LRGB2LUV', 'COLOR_LRGB2Lab', 'COLOR_LRGB2Luv', 'COLOR_LUV2BGR', 'COLOR_LUV2LBGR', 'COLOR_LUV2LRGB', 'COLOR_LUV2RGB', 'COLOR_Lab2BGR', 'COLOR_Lab2LBGR', 'COLOR_Lab2LRGB', 'COLOR_Lab2RGB', 'COLOR_Luv2BGR', 'COLOR_Luv2LBGR', 'COLOR_Luv2LRGB', 'COLOR_Luv2RGB', 'COLOR_M_RGBA2RGBA', 'COLOR_RGB2BGR', 'COLOR_RGB2BGR555', 'COLOR_RGB2BGR565', 'COLOR_RGB2BGRA', 'COLOR_RGB2GRAY', 'COLOR_RGB2HLS', 'COLOR_RGB2HLS_FULL', 'COLOR_RGB2HSV', 'COLOR_RGB2HSV_FULL', 'COLOR_RGB2LAB', 'COLOR_RGB2LUV', 'COLOR_RGB2Lab', 'COLOR_RGB2Luv', 'COLOR_RGB2RGBA', 'COLOR_RGB2XYZ', 'COLOR_RGB2YCR_CB', 'COLOR_RGB2YCrCb', 'COLOR_RGB2YUV', 'COLOR_RGB2YUV_I420', 'COLOR_RGB2YUV_IYUV', 'COLOR_RGB2YUV_UYNV', 'COLOR_RGB2YUV_UYVY', 'COLOR_RGB2YUV_Y422', 'COLOR_RGB2YUV_YUNV', 'COLOR_RGB2YUV_YUY2', 'COLOR_RGB2YUV_YUYV', 'COLOR_RGB2YUV_YV12', 'COLOR_RGB2YUV_YVYU', 'COLOR_RGBA2BGR', 'COLOR_RGBA2BGR555', 'COLOR_RGBA2BGR565', 'COLOR_RGBA2BGRA', 'COLOR_RGBA2GRAY', 'COLOR_RGBA2M_RGBA', 'COLOR_RGBA2RGB', 'COLOR_RGBA2YUV_I420', 'COLOR_RGBA2YUV_IYUV', 'COLOR_RGBA2YUV_UYNV', 'COLOR_RGBA2YUV_UYVY', 'COLOR_RGBA2YUV_Y422', 'COLOR_RGBA2YUV_YUNV', 'COLOR_RGBA2YUV_YUY2', 'COLOR_RGBA2YUV_YUYV', 'COLOR_RGBA2YUV_YV12', 'COLOR_RGBA2YUV_YVYU', 'COLOR_RGBA2mRGBA', 'COLOR_XYZ2BGR', 'COLOR_XYZ2RGB', 'COLOR_YCR_CB2BGR', 'COLOR_YCR_CB2RGB', 'COLOR_YCrCb2BGR', 'COLOR_YCrCb2RGB', 'COLOR_YUV2BGR', 'COLOR_YUV2BGRA_I420', 'COLOR_YUV2BGRA_IYUV', 'COLOR_YUV2BGRA_NV12', 'COLOR_YUV2BGRA_NV21', 'COLOR_YUV2BGRA_UYNV', 'COLOR_YUV2BGRA_UYVY', 'COLOR_YUV2BGRA_Y422', 'COLOR_YUV2BGRA_YUNV', 'COLOR_YUV2BGRA_YUY2', 'COLOR_YUV2BGRA_YUYV', 'COLOR_YUV2BGRA_YV12', 'COLOR_YUV2BGRA_YVYU', 'COLOR_YUV2BGR_I420', 'COLOR_YUV2BGR_IYUV', 'COLOR_YUV2BGR_NV12', 'COLOR_YUV2BGR_NV21', 'COLOR_YUV2BGR_UYNV', 'COLOR_YUV2BGR_UYVY', 'COLOR_YUV2BGR_Y422', 'COLOR_YUV2BGR_YUNV', 'COLOR_YUV2BGR_YUY2', 'COLOR_YUV2BGR_YUYV', 'COLOR_YUV2BGR_YV12', 'COLOR_YUV2BGR_YVYU', 'COLOR_YUV2GRAY_420', 'COLOR_YUV2GRAY_I420', 'COLOR_YUV2GRAY_IYUV', 'COLOR_YUV2GRAY_NV12', 'COLOR_YUV2GRAY_NV21', 'COLOR_YUV2GRAY_UYNV', 'COLOR_YUV2GRAY_UYVY', 'COLOR_YUV2GRAY_Y422', 'COLOR_YUV2GRAY_YUNV', 'COLOR_YUV2GRAY_YUY2', 'COLOR_YUV2GRAY_YUYV', 'COLOR_YUV2GRAY_YV12', 'COLOR_YUV2GRAY_YVYU', 'COLOR_YUV2RGB', 'COLOR_YUV2RGBA_I420', 'COLOR_YUV2RGBA_IYUV', 'COLOR_YUV2RGBA_NV12', 'COLOR_YUV2RGBA_NV21', 'COLOR_YUV2RGBA_UYNV', 'COLOR_YUV2RGBA_UYVY', 'COLOR_YUV2RGBA_Y422', 'COLOR_YUV2RGBA_YUNV', 'COLOR_YUV2RGBA_YUY2', 'COLOR_YUV2RGBA_YUYV', 'COLOR_YUV2RGBA_YV12', 'COLOR_YUV2RGBA_YVYU', 'COLOR_YUV2RGB_I420', 'COLOR_YUV2RGB_IYUV', 'COLOR_YUV2RGB_NV12', 'COLOR_YUV2RGB_NV21', 'COLOR_YUV2RGB_UYNV', 'COLOR_YUV2RGB_UYVY', 'COLOR_YUV2RGB_Y422', 'COLOR_YUV2RGB_YUNV', 'COLOR_YUV2RGB_YUY2', 'COLOR_YUV2RGB_YUYV', 'COLOR_YUV2RGB_YV12', 'COLOR_YUV2RGB_YVYU', 'COLOR_YUV420P2BGR', 'COLOR_YUV420P2BGRA', 'COLOR_YUV420P2GRAY', 'COLOR_YUV420P2RGB', 'COLOR_YUV420P2RGBA', 'COLOR_YUV420SP2BGR', 'COLOR_YUV420SP2BGRA', 'COLOR_YUV420SP2GRAY', 'COLOR_YUV420SP2RGB', 'COLOR_YUV420SP2RGBA', 'COLOR_YUV420p2BGR', 'COLOR_YUV420p2BGRA', 'COLOR_YUV420p2GRAY', 'COLOR_YUV420p2RGB', 'COLOR_YUV420p2RGBA', 'COLOR_YUV420sp2BGR', 'COLOR_YUV420sp2BGRA', 'COLOR_YUV420sp2GRAY', 'COLOR_YUV420sp2RGB', 'COLOR_YUV420sp2RGBA', 'COLOR_mRGBA2RGBA']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "flags = [i for i in dir(cv) if i.startswith('COLOR_')]\n",
    "print( flags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495d689-8b67-45e0-8908-52cc0bde8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object tracking\n",
    "green = np.uint8([[[0,255,0 ]]])\n",
    "hsv_green = cv.cvtColor(green,cv.COLOR_BGR2HSV)\n",
    "print( hsv_green )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d0656-5948-4757-9342-1c7d4cbbe6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    " \n",
    "while(1):\n",
    " \n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    " \n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    " \n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    " \n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv.inRange(hsv, lower_blue, upper_blue)\n",
    " \n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv.bitwise_and(frame,frame, mask= mask)\n",
    " \n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow('mask',mask)\n",
    "    cv.imshow('res',res)\n",
    "    k = cv.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    " \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e895d60-080e-4326-95e8-3e41fafbf965",
   "metadata": {},
   "source": [
    "## 2-8. Geometric Transformations\n",
    "### 2-8-1. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ef271-25e4-4663-a4fd-2983fc89653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('messi5.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "res = cv.resize(img,None,fx=2, fy=2, interpolation = cv.INTER_CUBIC)\n",
    " \n",
    "#OR\n",
    " \n",
    "height, width = img.shape[:2]\n",
    "res = cv.resize(img,(2*width, 2*height), interpolation = cv.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705b256-9322-4cdd-b235-2e7d2cc77697",
   "metadata": {},
   "source": [
    "### 2-8-2. Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899250a-ca51-42d1-a2cd-afa07e7c418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "rows,cols = img.shape\n",
    " \n",
    "M = np.float32([[1,0,100],[0,1,50]])\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    " \n",
    "cv.imshow('img',dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a99677b-fbf0-4b94-9189-c55350fb6d66",
   "metadata": {},
   "source": [
    "### 2-8-3. Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d5d0f-8cf0-477f-a053-004457c50646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "rows,cols = img.shape\n",
    " \n",
    "# cols-1 and rows-1 are the coordinate limits.\n",
    "M = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1)\n",
    "dst = cv.warpAffine(img,M,(cols,rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae05ba-4730-4d2b-9e48-fa9dc0c4fccc",
   "metadata": {},
   "source": [
    "### 2-8-4. Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e055079c-da4a-48b8-876f-54bad0b0bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Transformation\n",
    "img = cv.imread('drawing.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "rows,cols,ch = img.shape\n",
    " \n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    " \n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    " \n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15090d-8c3e-4dd4-ae63-9b0c857bc2ed",
   "metadata": {},
   "source": [
    "### 2-8-5. Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709248c-0b7b-426d-8394-8681b0884362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective Transformation\n",
    "img = cv.imread('sudoku.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "rows,cols,ch = img.shape\n",
    " \n",
    "pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    " \n",
    "M = cv.getPerspectiveTransform(pts1,pts2)\n",
    " \n",
    "dst = cv.warpPerspective(img,M,(300,300))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673746a-e908-4335-a115-9dc086cd68c5",
   "metadata": {},
   "source": [
    "## 2-9. Image Thresholding\n",
    "### 2-9-1. Simple Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024f53a-de26-4c90-bd7f-ba6bf00913a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('gradient.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "ret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "ret,thresh2 = cv.threshold(img,127,255,cv.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv.threshold(img,127,255,cv.THRESH_TRUNC)\n",
    "ret,thresh4 = cv.threshold(img,127,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img,127,255,cv.THRESH_TOZERO_INV)\n",
    " \n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    " \n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray',vmin=0,vmax=255)\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fc168-501d-4dee-b5e7-18ec0777ce72",
   "metadata": {},
   "source": [
    "### 2-9-2. Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a84ab-1916-4a06-a27d-3a1729e057e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('sudoku.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "img = cv.medianBlur(img,5)\n",
    " \n",
    "ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    " \n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    " \n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f8da5-a661-451a-8482-64f932023035",
   "metadata": {},
   "source": [
    "### 2-9-3. Otsu's Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25180e97-581b-439d-9d45-ae40c81b9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('noisy2.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# global thresholding\n",
    "ret1,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    " \n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    " \n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv.GaussianBlur(img,(5,5),0)\n",
    "ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    " \n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    " \n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a06d88-e57d-4e92-95f5-9c47a1c9eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('noisy2.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "blur = cv.GaussianBlur(img,(5,5),0)\n",
    " \n",
    "# find normalized_histogram, and its cumulative distribution function\n",
    "hist = cv.calcHist([blur],[0],None,[256],[0,256])\n",
    "hist_norm = hist.ravel()/hist.sum()\n",
    "Q = hist_norm.cumsum()\n",
    " \n",
    "bins = np.arange(256)\n",
    " \n",
    "fn_min = np.inf\n",
    "thresh = -1\n",
    " \n",
    "for i in range(1,256):\n",
    "    p1,p2 = np.hsplit(hist_norm,[i]) # probabilities\n",
    "    q1,q2 = Q[i],Q[255]-Q[i] # cum sum of classes\n",
    "    if q1 < 1.e-6 or q2 < 1.e-6:\n",
    "        continue\n",
    "    b1,b2 = np.hsplit(bins,[i]) # weights\n",
    " \n",
    "    # finding means and variances\n",
    "    m1,m2 = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2\n",
    "    v1,v2 = np.sum(((b1-m1)**2)*p1)/q1,np.sum(((b2-m2)**2)*p2)/q2\n",
    " \n",
    "    # calculates the minimization function\n",
    "    fn = v1*q1 + v2*q2\n",
    "    if fn < fn_min:\n",
    "        fn_min = fn\n",
    "        thresh = i\n",
    " \n",
    "# find otsu's threshold value with OpenCV function\n",
    "ret, otsu = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "print( \"{} {}\".format(thresh,ret) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7678e-d877-4fe0-8ce6-fbe5041a3d2b",
   "metadata": {},
   "source": [
    "## 2-10. Image Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc0ca9-062b-42e1-966a-6ce693a97cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('opencv_logo.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "dst = cv.filter2D(img,-1,kernel)\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63efc33-4333-4dc6-ae02-24b0849f3e3c",
   "metadata": {},
   "source": [
    "## 2-11. Image Smoothing\n",
    "### 2-11-1. Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afcce9-3557-4723-9f50-e95e77676d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('opencv-logo-white.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "blur = cv.blur(img,(5,5))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643902b7-c215-42ae-badd-c752cbf6d919",
   "metadata": {},
   "source": [
    "### 2-11-2. Gaussian Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6cd8c-4350-4d6d-8b9f-e4b7bc986960",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.GaussianBlur(img,(5,5),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a287f0f-b92e-4ef1-8c28-6e254a67e83e",
   "metadata": {},
   "source": [
    "### 2-11-3. Median Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17aadf8-b5f4-48f0-8228-3554b490322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cv.medianBlur(img,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31839fb0-528d-41e8-9f51-a48681914b70",
   "metadata": {},
   "source": [
    "### 2-11-4. Bilateral Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b24174-cc24-4650-9df1-ea5d78ebf071",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.bilateralFilter(img,9,75,75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5680cb0-34a7-4745-9c94-9beb9e7c3795",
   "metadata": {},
   "source": [
    "## 2-12. Morphological Transformations\n",
    "### 2-12-1. Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd620e38-bca9-4934-af28-308cb6e8bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "img = cv.imread('j.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv.erode(img,kernel,iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17226b6-7ccc-43ec-b2d4-3481b25431c1",
   "metadata": {},
   "source": [
    "### 2-12-2. Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6385c-29da-4173-9820-62bb9e773f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv.dilate(img,kernel,iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1051de-0283-49b8-b84c-2d1cdd35e269",
   "metadata": {},
   "source": [
    "### 2-12-3. Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97591380-73fb-4ac4-8e40-f3d78ca06c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c8166-a1d3-4740-9d43-41ce023bbdcc",
   "metadata": {},
   "source": [
    "### 2-12-4. Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14e969-9f91-4595-83f0-ac7a02d4a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5444fb-cbc7-4cb8-a1fc-18d519748580",
   "metadata": {},
   "source": [
    "### 2-12-5. Morphological Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5dece4-354c-4cd8-8078-4fc66a0a1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba298c-5f3e-4a3b-b7d4-f814916bf5dc",
   "metadata": {},
   "source": [
    "### 2-12-6. Top Hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b51921-2cbf-4436-a697-4652af7c4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "tophat = cv.morphologyEx(img, cv.MORPH_TOPHAT, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9a9de-02f2-4823-a376-a3104b278939",
   "metadata": {},
   "source": [
    "### 2-12-7. Black Hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a2f4c-a241-45e5-bd01-10d03d175981",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackhat = cv.morphologyEx(img, cv.MORPH_BLACKHAT, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d10bc9-af6b-4f65-a04e-8dec98af0253",
   "metadata": {},
   "source": [
    "### 2-12-8. Structuring Elements\n",
    "1. `cv2.getStructuringElement(shape, ksize, anchor=Point(-1,-1))`: Returns a structuring element of the specified size and shape for morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade981fc-0cf0-4d33-a091-e8564d15b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectangular Kernel\n",
    "cv.getStructuringElement(cv.MORPH_RECT,(5,5))\n",
    "array([[1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1]], dtype=uint8)\n",
    " \n",
    "# Elliptical Kernel\n",
    "cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "array([[0, 0, 1, 0, 0],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [0, 0, 1, 0, 0]], dtype=uint8)\n",
    " \n",
    "# Cross-shaped Kernel\n",
    "cv.getStructuringElement(cv.MORPH_CROSS,(5,5))\n",
    "array([[0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0]], dtype=uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fba59-74c8-45b5-bcd4-ed9a5eea9c69",
   "metadata": {},
   "source": [
    "## 2-13. Image Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3062a51-979a-43df-8db0-2d9ecfce4b81",
   "metadata": {},
   "source": [
    "## 2-14. Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ee77d-ff10-4b03-af58-5d51bcd145e4",
   "metadata": {},
   "source": [
    "## 2-15. Image Pyramids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8fc8a-bb4a-4a09-85d5-dbe6123813fc",
   "metadata": {},
   "source": [
    "## 2-16. Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f91c1-0dc0-415a-a118-716d525011aa",
   "metadata": {},
   "source": [
    "## 2-17. Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce081757-0c72-45cd-a941-85ab393aa601",
   "metadata": {},
   "source": [
    "## 2-18. Image Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12acbcd2-212f-4afd-99af-66aa7c3520ae",
   "metadata": {},
   "source": [
    "## 2-19. Template Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056ee98-e99f-4a63-8ce7-4dab9117149e",
   "metadata": {},
   "source": [
    "## 2-20. Hough Line Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b65240-ce12-447c-aa4a-60821667b0e2",
   "metadata": {},
   "source": [
    "## 2-21. Hough Circle Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d53c1-0088-4aae-9eb8-337929a1920a",
   "metadata": {},
   "source": [
    "## 2-22. Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0081ac-ecad-4c1d-a165-d2240fc92fa7",
   "metadata": {},
   "source": [
    "## 2-23. Interactive Foreground Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f6a284-d962-4e39-a4d3-5d39a91f34c3",
   "metadata": {},
   "source": [
    "# 10. Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f425e55d-08fc-448e-b033-dce74143cce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6701da-0406-45f8-8f0b-0222f3b8f97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc1d63a-6103-4ef4-af23-ae9459bd1e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
