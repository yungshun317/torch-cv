{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71b20d3-359f-4762-a5ac-f872999f7f0b",
   "metadata": {},
   "source": [
    "- **Graphical User Interface**\n",
    "- **Image Processing**\n",
    "- **Feature Detection & Description**\n",
    "- **Video Analysis**\n",
    "- **Camera Calibration & 3D Reconstruction**\n",
    "- **Machine Learning**\n",
    "- **Computational Photography**\n",
    "- **Object Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86d384-8c66-4e56-a2e5-296d301a3bb9",
   "metadata": {},
   "source": [
    "# 1. Graphical User Interface (GUI)\n",
    "## 1-1. Load, Display & Save Images\n",
    "1. `cv2.imread(filename, flags)`\n",
    "    - `flags`\n",
    "        - `cv2.IMREAD_COLOR`\n",
    "        - `cv2.IMREAD_UNCHANGED`\n",
    "        - `cv2.IMREAD_GRAYSCALE`\n",
    "\n",
    "[OpenCV Samples](https://github.com/opencv/opencv/tree/master/samples/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13fd89bd-3968-4ff1-b2f4-b34e26c571a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@347.096] global samples.cpp:61 findFile cv::samples::findFile('starry_night.jpg') => '/home/yungshun317/workspace/py/torch-cv/data/starry_night.jpg'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "cv2.samples.addSamplesDataSearchPath(\"/home/yungshun317/workspace/py/torch-cv/data/\")\n",
    "img = cv2.imread(cv2.samples.findFile(\"starry_night.jpg\"), cv2.IMREAD_UNCHANGED)\n",
    " \n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    " \n",
    "cv2.imshow(\"Display window\", img)\n",
    "k = cv2.waitKey(0)\n",
    " \n",
    "if k == ord(\"s\"):\n",
    "    cv2.imwrite(\"outputs/starry_night.png\", img)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162d985-42e7-44c6-83cf-e2a3b7eff5c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "955b391f-932a-4da7-8d55-b6057b2c997e",
   "metadata": {},
   "source": [
    "## 1-2. Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1d494f-8e6d-4497-afb5-33b60bfa9d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Line\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "# Create a black image\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    " \n",
    "# Draw a diagonal blue line with thickness of 5 px\n",
    "cv.line(img,(0,0),(511,511),(255,0,0),5)\n",
    "\n",
    "cv.imwrite(\"outputs/line.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e5421-de22-423c-a288-066e3cd8122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectangle\n",
    "cv.rectangle(img,(384,0),(510,128),(0,255,0),3)\n",
    "\n",
    "cv.imwrite(\"outputs/rectangle.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cd3c7-7f6f-4fe5-a884-b8d9c6f90d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circle\n",
    "cv.circle(img,(447,63), 63, (0,0,255), -1)\n",
    "\n",
    "cv.imwrite(\"outputs/circle.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962cdb2-5dc3-45a8-8969-9b44fc753fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ellipse\n",
    "cv.ellipse(img,(256,256),(100,50),0,0,180,255,-1)\n",
    "\n",
    "cv.imwrite(\"outputs/ellipse.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b6cc5-24bb-425b-bf8e-a4aca4e14a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polygon\n",
    "pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv.polylines(img,[pts],True,(0,255,255))\n",
    "\n",
    "cv.imwrite(\"outputs/polygon.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de9af4-1303-403a-a5d7-2a2c30816ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "cv.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,cv.LINE_AA)\n",
    "\n",
    "cv.imwrite(\"outputs/text.png\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc569a65-3fde-4e2d-b9f1-358a00264380",
   "metadata": {},
   "source": [
    "## 1-3. Paint Brush \n",
    "1. `setMouseCallback(winname, onMouse, userdata=0)`: Sets mouse handler for the specified window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ff7dbe-257e-4464-bef2-86b910ee4e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "events = [i for i in dir(cv) if 'EVENT' in i]\n",
    "print( events )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a6ad35-32fc-4841-aea1-dc8e4bd83dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    if event == cv.EVENT_LBUTTONDBLCLK:\n",
    "        cv.circle(img,(x,y),100,(255,0,0),-1)\n",
    " \n",
    "# Create a black image, a window and bind the function to window\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image',draw_circle)\n",
    "\n",
    "# Break when `ESC` is clicked\n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    if cv.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa07cf15-b2e4-4f60-b1af-799fa3584e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "ix,iy = -1,-1\n",
    " \n",
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global ix,iy,drawing,mode\n",
    " \n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    " \n",
    "    elif event == cv.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            if mode == True:\n",
    "                cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "            else:\n",
    "                cv.circle(img,(x,y),5,(0,0,255),-1)\n",
    " \n",
    "    elif event == cv.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode == True:\n",
    "            cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "        else:\n",
    "            cv.circle(img,(x,y),5,(0,0,255),-1)\n",
    "\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image',draw_circle)\n",
    " \n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    " \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033667f-50f6-47da-af8d-ad9b6933cd06",
   "metadata": {},
   "source": [
    "## 1-4. Color Palette\n",
    "1. `cv2.createTrackbar(trackbarname, winname, value, count, onChange=0, userdata=0)`: Creates a trackbar & attaches it to the specified window.\n",
    "2. `cv2.getTrackbarPos(trackbarname, winname)`: Returns the trackbar position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad3bef3-422e-451a-94e9-e267df18289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv.namedWindow('image')\n",
    " \n",
    "# create trackbars for color change\n",
    "cv.createTrackbar('R','image',0,255,nothing)\n",
    " \n",
    "cv.createTrackbar('G','image',0,255,nothing)\n",
    "cv.createTrackbar('B','image',0,255,nothing)\n",
    " \n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv.createTrackbar(switch, 'image',0,1,nothing)\n",
    " \n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    " \n",
    "    # get current positions of four trackbars\n",
    "    r = cv.getTrackbarPos('R','image')\n",
    "    g = cv.getTrackbarPos('G','image')\n",
    "    b = cv.getTrackbarPos('B','image')\n",
    "    s = cv.getTrackbarPos(switch,'image')\n",
    " \n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    " \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c47141-8a7a-4d21-ad35-8f6f767c8761",
   "metadata": {},
   "source": [
    "## 1-5. Capture Videos from Cameras\n",
    "1. `cv2.VideoCapture()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37664a1-b58c-43c3-901a-e6b59b06d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4385d-b74b-4c01-9924-b8a4ce7a5201",
   "metadata": {},
   "source": [
    "## 1-6. Play Videos from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0ba4e-72c6-45f0-be38-7ad40961b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture('data/vtest.avi')\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    " \n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a905fdd-e957-41c4-96d6-8dd9a6c9b5d1",
   "metadata": {},
   "source": [
    "## 1-7. Write Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b0482-9e3b-49df-b931-3f99f226e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    " \n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter('outputs/output.avi', fourcc, 20.0, (640,  480))\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    frame = cv.flip(frame, 0)\n",
    " \n",
    "    # write the flipped frame\n",
    "    out.write(frame)\n",
    " \n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0942a-f937-4d43-8a95-2658ed6fb552",
   "metadata": {},
   "source": [
    "# 2. Image Processing\n",
    "## 2-1. Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583ee34f-d036-41a4-89fa-ebf918036eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157 166 200]\n"
     ]
    }
   ],
   "source": [
    "# Access pixel values\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('data/messi5.jpg')\n",
    "px = img[100,100]\n",
    "print( px )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc0665e5-708f-4e70-8714-bc8d74451ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "blue = img[100,100,0]\n",
    "print( blue )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b629ca24-9824-4265-8d7f-4182653c1d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "# Modify pixel values\n",
    "img[100,100] = [255,255,255]\n",
    "print( img[100,100] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f923cc-ca43-4f52-b706-86f1fa66a5fa",
   "metadata": {},
   "source": [
    "## 2-2. Image Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a932e2c1-ab56-487d-a288-c227d3af82ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 548, 3)\n"
     ]
    }
   ],
   "source": [
    "# Image Properties\n",
    "print( img.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934d65f-e328-4030-b2e9-898249c2d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( img.size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b15d07-fba8-4e09-b3b3-7b2a0c3e90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( img.dtype )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c27ff-39f9-4dc1-9526-6d396a88c2ae",
   "metadata": {},
   "source": [
    "## 2-3. Region of Images (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45556f0d-5893-4b07-99d4-18b170745b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI\n",
    "ball = img[280:340, 330:390]\n",
    "img[273:333, 100:160] = ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03592b-dde1-40b3-b3e2-accdeb027371",
   "metadata": {},
   "source": [
    "## 2-4. Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9715f33-5702-4091-ad79-9f95f0979598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels\n",
    "b,g,r = cv.split(img)\n",
    "img = cv.merge((b,g,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6bd86b-21ea-40b2-bb89-cb830b48de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859774fc-257a-4ad8-b3b6-4f98dd7bd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:,:,2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622e681-be9e-497e-bf43-0a8908652b53",
   "metadata": {},
   "source": [
    "## 2-5. Borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0df8f-1d92-46bb-8843-e8616603b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borders\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "BLUE = [255,0,0]\n",
    " \n",
    "img1 = cv.imread('opencv-logo.png')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "replicate = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REPLICATE)\n",
    "reflect = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT)\n",
    "reflect101 = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT_101)\n",
    "wrap = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_WRAP)\n",
    "constant= cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_CONSTANT,value=BLUE)\n",
    " \n",
    "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
    "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
    "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
    "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
    "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
    "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745282f1-6620-4ba3-ac9e-4ba066c40bda",
   "metadata": {},
   "source": [
    "## 2-6. Arithmetic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf0d9a-e9c9-40e4-8b76-afddc6b9570e",
   "metadata": {},
   "source": [
    "### 2-6-1. Image Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2aa93-e93f-46b7-974f-c7a223b78d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.uint8([250])\n",
    "y = np.uint8([10])\n",
    " \n",
    "print( cv.add(x,y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6976c6-5b7e-48c6-85fb-b626510ebe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( x+y ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100a029-250c-4354-b0f8-3505c402f649",
   "metadata": {},
   "source": [
    "### 2-6-2. Image Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d7e96-f636-48e2-b089-138b05b58221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image blending\n",
    "img1 = cv.imread('ml.png')\n",
    "img2 = cv.imread('opencv-logo.png')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert img2 is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "dst = cv.addWeighted(img1,0.7,img2,0.3,0)\n",
    " \n",
    "cv.imshow('dst',dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e701f-17bf-41ce-8e20-20f6003df233",
   "metadata": {},
   "source": [
    "### 2-6-3. Bitwise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65da21d-2cbb-44a5-8850-3a4d9840ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitwise operations\n",
    "# Load two images\n",
    "img1 = cv.imread('messi5.jpg')\n",
    "img2 = cv.imread('opencv-logo-white.png')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert img2 is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# I want to put logo on top-left corner, So I create a ROI\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols]\n",
    " \n",
    "# Now create a mask of logo and create its inverse mask also\n",
    "img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(img2gray, 10, 255, cv.THRESH_BINARY)\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    " \n",
    "# Now black-out the area of logo in ROI\n",
    "img1_bg = cv.bitwise_and(roi,roi,mask = mask_inv)\n",
    " \n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv.bitwise_and(img2,img2,mask = mask)\n",
    " \n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv.add(img1_bg,img2_fg)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    " \n",
    "cv.imshow('res',img1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d58941-13f8-435a-842e-227e712ba968",
   "metadata": {},
   "source": [
    "## 2-7. Color Spaces\n",
    "1. `cv2.cvtColor(src, dst, code, dstCn=0, hint=cv2.ALGO_HINT_DEFAULT)`: Converts an image from one color space to another.\n",
    "    - `hint`\n",
    "        - `cv2.ALGO_HINT_DEFAULT`\n",
    "        - `cv2.ALGO_HINT_ACCURATE`\n",
    "        - `cv2.ALGO_HINT_APPROX`\n",
    "3. `cv2.inRange(src, lowerb, upperb, dst)`: Checks if array elements lie between the elements of 2 other arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc91e413-3070-46ca-9323-3b01babb794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COLOR_BAYER_BG2BGR', 'COLOR_BAYER_BG2BGRA', 'COLOR_BAYER_BG2BGR_EA', 'COLOR_BAYER_BG2BGR_VNG', 'COLOR_BAYER_BG2GRAY', 'COLOR_BAYER_BG2RGB', 'COLOR_BAYER_BG2RGBA', 'COLOR_BAYER_BG2RGB_EA', 'COLOR_BAYER_BG2RGB_VNG', 'COLOR_BAYER_BGGR2BGR', 'COLOR_BAYER_BGGR2BGRA', 'COLOR_BAYER_BGGR2BGR_EA', 'COLOR_BAYER_BGGR2BGR_VNG', 'COLOR_BAYER_BGGR2GRAY', 'COLOR_BAYER_BGGR2RGB', 'COLOR_BAYER_BGGR2RGBA', 'COLOR_BAYER_BGGR2RGB_EA', 'COLOR_BAYER_BGGR2RGB_VNG', 'COLOR_BAYER_GB2BGR', 'COLOR_BAYER_GB2BGRA', 'COLOR_BAYER_GB2BGR_EA', 'COLOR_BAYER_GB2BGR_VNG', 'COLOR_BAYER_GB2GRAY', 'COLOR_BAYER_GB2RGB', 'COLOR_BAYER_GB2RGBA', 'COLOR_BAYER_GB2RGB_EA', 'COLOR_BAYER_GB2RGB_VNG', 'COLOR_BAYER_GBRG2BGR', 'COLOR_BAYER_GBRG2BGRA', 'COLOR_BAYER_GBRG2BGR_EA', 'COLOR_BAYER_GBRG2BGR_VNG', 'COLOR_BAYER_GBRG2GRAY', 'COLOR_BAYER_GBRG2RGB', 'COLOR_BAYER_GBRG2RGBA', 'COLOR_BAYER_GBRG2RGB_EA', 'COLOR_BAYER_GBRG2RGB_VNG', 'COLOR_BAYER_GR2BGR', 'COLOR_BAYER_GR2BGRA', 'COLOR_BAYER_GR2BGR_EA', 'COLOR_BAYER_GR2BGR_VNG', 'COLOR_BAYER_GR2GRAY', 'COLOR_BAYER_GR2RGB', 'COLOR_BAYER_GR2RGBA', 'COLOR_BAYER_GR2RGB_EA', 'COLOR_BAYER_GR2RGB_VNG', 'COLOR_BAYER_GRBG2BGR', 'COLOR_BAYER_GRBG2BGRA', 'COLOR_BAYER_GRBG2BGR_EA', 'COLOR_BAYER_GRBG2BGR_VNG', 'COLOR_BAYER_GRBG2GRAY', 'COLOR_BAYER_GRBG2RGB', 'COLOR_BAYER_GRBG2RGBA', 'COLOR_BAYER_GRBG2RGB_EA', 'COLOR_BAYER_GRBG2RGB_VNG', 'COLOR_BAYER_RG2BGR', 'COLOR_BAYER_RG2BGRA', 'COLOR_BAYER_RG2BGR_EA', 'COLOR_BAYER_RG2BGR_VNG', 'COLOR_BAYER_RG2GRAY', 'COLOR_BAYER_RG2RGB', 'COLOR_BAYER_RG2RGBA', 'COLOR_BAYER_RG2RGB_EA', 'COLOR_BAYER_RG2RGB_VNG', 'COLOR_BAYER_RGGB2BGR', 'COLOR_BAYER_RGGB2BGRA', 'COLOR_BAYER_RGGB2BGR_EA', 'COLOR_BAYER_RGGB2BGR_VNG', 'COLOR_BAYER_RGGB2GRAY', 'COLOR_BAYER_RGGB2RGB', 'COLOR_BAYER_RGGB2RGBA', 'COLOR_BAYER_RGGB2RGB_EA', 'COLOR_BAYER_RGGB2RGB_VNG', 'COLOR_BGR2BGR555', 'COLOR_BGR2BGR565', 'COLOR_BGR2BGRA', 'COLOR_BGR2GRAY', 'COLOR_BGR2HLS', 'COLOR_BGR2HLS_FULL', 'COLOR_BGR2HSV', 'COLOR_BGR2HSV_FULL', 'COLOR_BGR2LAB', 'COLOR_BGR2LUV', 'COLOR_BGR2Lab', 'COLOR_BGR2Luv', 'COLOR_BGR2RGB', 'COLOR_BGR2RGBA', 'COLOR_BGR2XYZ', 'COLOR_BGR2YCR_CB', 'COLOR_BGR2YCrCb', 'COLOR_BGR2YUV', 'COLOR_BGR2YUV_I420', 'COLOR_BGR2YUV_IYUV', 'COLOR_BGR2YUV_UYNV', 'COLOR_BGR2YUV_UYVY', 'COLOR_BGR2YUV_Y422', 'COLOR_BGR2YUV_YUNV', 'COLOR_BGR2YUV_YUY2', 'COLOR_BGR2YUV_YUYV', 'COLOR_BGR2YUV_YV12', 'COLOR_BGR2YUV_YVYU', 'COLOR_BGR5552BGR', 'COLOR_BGR5552BGRA', 'COLOR_BGR5552GRAY', 'COLOR_BGR5552RGB', 'COLOR_BGR5552RGBA', 'COLOR_BGR5652BGR', 'COLOR_BGR5652BGRA', 'COLOR_BGR5652GRAY', 'COLOR_BGR5652RGB', 'COLOR_BGR5652RGBA', 'COLOR_BGRA2BGR', 'COLOR_BGRA2BGR555', 'COLOR_BGRA2BGR565', 'COLOR_BGRA2GRAY', 'COLOR_BGRA2RGB', 'COLOR_BGRA2RGBA', 'COLOR_BGRA2YUV_I420', 'COLOR_BGRA2YUV_IYUV', 'COLOR_BGRA2YUV_UYNV', 'COLOR_BGRA2YUV_UYVY', 'COLOR_BGRA2YUV_Y422', 'COLOR_BGRA2YUV_YUNV', 'COLOR_BGRA2YUV_YUY2', 'COLOR_BGRA2YUV_YUYV', 'COLOR_BGRA2YUV_YV12', 'COLOR_BGRA2YUV_YVYU', 'COLOR_BayerBG2BGR', 'COLOR_BayerBG2BGRA', 'COLOR_BayerBG2BGR_EA', 'COLOR_BayerBG2BGR_VNG', 'COLOR_BayerBG2GRAY', 'COLOR_BayerBG2RGB', 'COLOR_BayerBG2RGBA', 'COLOR_BayerBG2RGB_EA', 'COLOR_BayerBG2RGB_VNG', 'COLOR_BayerBGGR2BGR', 'COLOR_BayerBGGR2BGRA', 'COLOR_BayerBGGR2BGR_EA', 'COLOR_BayerBGGR2BGR_VNG', 'COLOR_BayerBGGR2GRAY', 'COLOR_BayerBGGR2RGB', 'COLOR_BayerBGGR2RGBA', 'COLOR_BayerBGGR2RGB_EA', 'COLOR_BayerBGGR2RGB_VNG', 'COLOR_BayerGB2BGR', 'COLOR_BayerGB2BGRA', 'COLOR_BayerGB2BGR_EA', 'COLOR_BayerGB2BGR_VNG', 'COLOR_BayerGB2GRAY', 'COLOR_BayerGB2RGB', 'COLOR_BayerGB2RGBA', 'COLOR_BayerGB2RGB_EA', 'COLOR_BayerGB2RGB_VNG', 'COLOR_BayerGBRG2BGR', 'COLOR_BayerGBRG2BGRA', 'COLOR_BayerGBRG2BGR_EA', 'COLOR_BayerGBRG2BGR_VNG', 'COLOR_BayerGBRG2GRAY', 'COLOR_BayerGBRG2RGB', 'COLOR_BayerGBRG2RGBA', 'COLOR_BayerGBRG2RGB_EA', 'COLOR_BayerGBRG2RGB_VNG', 'COLOR_BayerGR2BGR', 'COLOR_BayerGR2BGRA', 'COLOR_BayerGR2BGR_EA', 'COLOR_BayerGR2BGR_VNG', 'COLOR_BayerGR2GRAY', 'COLOR_BayerGR2RGB', 'COLOR_BayerGR2RGBA', 'COLOR_BayerGR2RGB_EA', 'COLOR_BayerGR2RGB_VNG', 'COLOR_BayerGRBG2BGR', 'COLOR_BayerGRBG2BGRA', 'COLOR_BayerGRBG2BGR_EA', 'COLOR_BayerGRBG2BGR_VNG', 'COLOR_BayerGRBG2GRAY', 'COLOR_BayerGRBG2RGB', 'COLOR_BayerGRBG2RGBA', 'COLOR_BayerGRBG2RGB_EA', 'COLOR_BayerGRBG2RGB_VNG', 'COLOR_BayerRG2BGR', 'COLOR_BayerRG2BGRA', 'COLOR_BayerRG2BGR_EA', 'COLOR_BayerRG2BGR_VNG', 'COLOR_BayerRG2GRAY', 'COLOR_BayerRG2RGB', 'COLOR_BayerRG2RGBA', 'COLOR_BayerRG2RGB_EA', 'COLOR_BayerRG2RGB_VNG', 'COLOR_BayerRGGB2BGR', 'COLOR_BayerRGGB2BGRA', 'COLOR_BayerRGGB2BGR_EA', 'COLOR_BayerRGGB2BGR_VNG', 'COLOR_BayerRGGB2GRAY', 'COLOR_BayerRGGB2RGB', 'COLOR_BayerRGGB2RGBA', 'COLOR_BayerRGGB2RGB_EA', 'COLOR_BayerRGGB2RGB_VNG', 'COLOR_COLORCVT_MAX', 'COLOR_GRAY2BGR', 'COLOR_GRAY2BGR555', 'COLOR_GRAY2BGR565', 'COLOR_GRAY2BGRA', 'COLOR_GRAY2RGB', 'COLOR_GRAY2RGBA', 'COLOR_HLS2BGR', 'COLOR_HLS2BGR_FULL', 'COLOR_HLS2RGB', 'COLOR_HLS2RGB_FULL', 'COLOR_HSV2BGR', 'COLOR_HSV2BGR_FULL', 'COLOR_HSV2RGB', 'COLOR_HSV2RGB_FULL', 'COLOR_LAB2BGR', 'COLOR_LAB2LBGR', 'COLOR_LAB2LRGB', 'COLOR_LAB2RGB', 'COLOR_LBGR2LAB', 'COLOR_LBGR2LUV', 'COLOR_LBGR2Lab', 'COLOR_LBGR2Luv', 'COLOR_LRGB2LAB', 'COLOR_LRGB2LUV', 'COLOR_LRGB2Lab', 'COLOR_LRGB2Luv', 'COLOR_LUV2BGR', 'COLOR_LUV2LBGR', 'COLOR_LUV2LRGB', 'COLOR_LUV2RGB', 'COLOR_Lab2BGR', 'COLOR_Lab2LBGR', 'COLOR_Lab2LRGB', 'COLOR_Lab2RGB', 'COLOR_Luv2BGR', 'COLOR_Luv2LBGR', 'COLOR_Luv2LRGB', 'COLOR_Luv2RGB', 'COLOR_M_RGBA2RGBA', 'COLOR_RGB2BGR', 'COLOR_RGB2BGR555', 'COLOR_RGB2BGR565', 'COLOR_RGB2BGRA', 'COLOR_RGB2GRAY', 'COLOR_RGB2HLS', 'COLOR_RGB2HLS_FULL', 'COLOR_RGB2HSV', 'COLOR_RGB2HSV_FULL', 'COLOR_RGB2LAB', 'COLOR_RGB2LUV', 'COLOR_RGB2Lab', 'COLOR_RGB2Luv', 'COLOR_RGB2RGBA', 'COLOR_RGB2XYZ', 'COLOR_RGB2YCR_CB', 'COLOR_RGB2YCrCb', 'COLOR_RGB2YUV', 'COLOR_RGB2YUV_I420', 'COLOR_RGB2YUV_IYUV', 'COLOR_RGB2YUV_UYNV', 'COLOR_RGB2YUV_UYVY', 'COLOR_RGB2YUV_Y422', 'COLOR_RGB2YUV_YUNV', 'COLOR_RGB2YUV_YUY2', 'COLOR_RGB2YUV_YUYV', 'COLOR_RGB2YUV_YV12', 'COLOR_RGB2YUV_YVYU', 'COLOR_RGBA2BGR', 'COLOR_RGBA2BGR555', 'COLOR_RGBA2BGR565', 'COLOR_RGBA2BGRA', 'COLOR_RGBA2GRAY', 'COLOR_RGBA2M_RGBA', 'COLOR_RGBA2RGB', 'COLOR_RGBA2YUV_I420', 'COLOR_RGBA2YUV_IYUV', 'COLOR_RGBA2YUV_UYNV', 'COLOR_RGBA2YUV_UYVY', 'COLOR_RGBA2YUV_Y422', 'COLOR_RGBA2YUV_YUNV', 'COLOR_RGBA2YUV_YUY2', 'COLOR_RGBA2YUV_YUYV', 'COLOR_RGBA2YUV_YV12', 'COLOR_RGBA2YUV_YVYU', 'COLOR_RGBA2mRGBA', 'COLOR_XYZ2BGR', 'COLOR_XYZ2RGB', 'COLOR_YCR_CB2BGR', 'COLOR_YCR_CB2RGB', 'COLOR_YCrCb2BGR', 'COLOR_YCrCb2RGB', 'COLOR_YUV2BGR', 'COLOR_YUV2BGRA_I420', 'COLOR_YUV2BGRA_IYUV', 'COLOR_YUV2BGRA_NV12', 'COLOR_YUV2BGRA_NV21', 'COLOR_YUV2BGRA_UYNV', 'COLOR_YUV2BGRA_UYVY', 'COLOR_YUV2BGRA_Y422', 'COLOR_YUV2BGRA_YUNV', 'COLOR_YUV2BGRA_YUY2', 'COLOR_YUV2BGRA_YUYV', 'COLOR_YUV2BGRA_YV12', 'COLOR_YUV2BGRA_YVYU', 'COLOR_YUV2BGR_I420', 'COLOR_YUV2BGR_IYUV', 'COLOR_YUV2BGR_NV12', 'COLOR_YUV2BGR_NV21', 'COLOR_YUV2BGR_UYNV', 'COLOR_YUV2BGR_UYVY', 'COLOR_YUV2BGR_Y422', 'COLOR_YUV2BGR_YUNV', 'COLOR_YUV2BGR_YUY2', 'COLOR_YUV2BGR_YUYV', 'COLOR_YUV2BGR_YV12', 'COLOR_YUV2BGR_YVYU', 'COLOR_YUV2GRAY_420', 'COLOR_YUV2GRAY_I420', 'COLOR_YUV2GRAY_IYUV', 'COLOR_YUV2GRAY_NV12', 'COLOR_YUV2GRAY_NV21', 'COLOR_YUV2GRAY_UYNV', 'COLOR_YUV2GRAY_UYVY', 'COLOR_YUV2GRAY_Y422', 'COLOR_YUV2GRAY_YUNV', 'COLOR_YUV2GRAY_YUY2', 'COLOR_YUV2GRAY_YUYV', 'COLOR_YUV2GRAY_YV12', 'COLOR_YUV2GRAY_YVYU', 'COLOR_YUV2RGB', 'COLOR_YUV2RGBA_I420', 'COLOR_YUV2RGBA_IYUV', 'COLOR_YUV2RGBA_NV12', 'COLOR_YUV2RGBA_NV21', 'COLOR_YUV2RGBA_UYNV', 'COLOR_YUV2RGBA_UYVY', 'COLOR_YUV2RGBA_Y422', 'COLOR_YUV2RGBA_YUNV', 'COLOR_YUV2RGBA_YUY2', 'COLOR_YUV2RGBA_YUYV', 'COLOR_YUV2RGBA_YV12', 'COLOR_YUV2RGBA_YVYU', 'COLOR_YUV2RGB_I420', 'COLOR_YUV2RGB_IYUV', 'COLOR_YUV2RGB_NV12', 'COLOR_YUV2RGB_NV21', 'COLOR_YUV2RGB_UYNV', 'COLOR_YUV2RGB_UYVY', 'COLOR_YUV2RGB_Y422', 'COLOR_YUV2RGB_YUNV', 'COLOR_YUV2RGB_YUY2', 'COLOR_YUV2RGB_YUYV', 'COLOR_YUV2RGB_YV12', 'COLOR_YUV2RGB_YVYU', 'COLOR_YUV420P2BGR', 'COLOR_YUV420P2BGRA', 'COLOR_YUV420P2GRAY', 'COLOR_YUV420P2RGB', 'COLOR_YUV420P2RGBA', 'COLOR_YUV420SP2BGR', 'COLOR_YUV420SP2BGRA', 'COLOR_YUV420SP2GRAY', 'COLOR_YUV420SP2RGB', 'COLOR_YUV420SP2RGBA', 'COLOR_YUV420p2BGR', 'COLOR_YUV420p2BGRA', 'COLOR_YUV420p2GRAY', 'COLOR_YUV420p2RGB', 'COLOR_YUV420p2RGBA', 'COLOR_YUV420sp2BGR', 'COLOR_YUV420sp2BGRA', 'COLOR_YUV420sp2GRAY', 'COLOR_YUV420sp2RGB', 'COLOR_YUV420sp2RGBA', 'COLOR_mRGBA2RGBA']\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "flags = [i for i in dir(cv) if i.startswith('COLOR_')]\n",
    "print( flags )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf162908-e53c-42be-ad14-a52139331cca",
   "metadata": {},
   "source": [
    "### 2-7-1. Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495d689-8b67-45e0-8908-52cc0bde8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object tracking\n",
    "green = np.uint8([[[0,255,0 ]]])\n",
    "hsv_green = cv.cvtColor(green,cv.COLOR_BGR2HSV)\n",
    "print( hsv_green )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d0656-5948-4757-9342-1c7d4cbbe6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    " \n",
    "while(1):\n",
    " \n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    " \n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    " \n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    " \n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv.inRange(hsv, lower_blue, upper_blue)\n",
    " \n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv.bitwise_and(frame,frame, mask= mask)\n",
    " \n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow('mask',mask)\n",
    "    cv.imshow('res',res)\n",
    "    k = cv.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    " \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e895d60-080e-4326-95e8-3e41fafbf965",
   "metadata": {},
   "source": [
    "## 2-8. Geometric Transformations\n",
    "### 2-8-1. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ef271-25e4-4663-a4fd-2983fc89653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('messi5.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "res = cv.resize(img,None,fx=2, fy=2, interpolation = cv.INTER_CUBIC)\n",
    " \n",
    "#OR\n",
    " \n",
    "height, width = img.shape[:2]\n",
    "res = cv.resize(img,(2*width, 2*height), interpolation = cv.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705b256-9322-4cdd-b235-2e7d2cc77697",
   "metadata": {},
   "source": [
    "### 2-8-2. Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899250a-ca51-42d1-a2cd-afa07e7c418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "rows,cols = img.shape\n",
    " \n",
    "M = np.float32([[1,0,100],[0,1,50]])\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    " \n",
    "cv.imshow('img',dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a99677b-fbf0-4b94-9189-c55350fb6d66",
   "metadata": {},
   "source": [
    "### 2-8-3. Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d5d0f-8cf0-477f-a053-004457c50646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "rows,cols = img.shape\n",
    " \n",
    "# cols-1 and rows-1 are the coordinate limits.\n",
    "M = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1)\n",
    "dst = cv.warpAffine(img,M,(cols,rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae05ba-4730-4d2b-9e48-fa9dc0c4fccc",
   "metadata": {},
   "source": [
    "### 2-8-4. Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e055079c-da4a-48b8-876f-54bad0b0bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Transformation\n",
    "img = cv.imread('drawing.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "rows,cols,ch = img.shape\n",
    " \n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    " \n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    " \n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15090d-8c3e-4dd4-ae63-9b0c857bc2ed",
   "metadata": {},
   "source": [
    "### 2-8-5. Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709248c-0b7b-426d-8394-8681b0884362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective Transformation\n",
    "img = cv.imread('sudoku.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "rows,cols,ch = img.shape\n",
    " \n",
    "pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    " \n",
    "M = cv.getPerspectiveTransform(pts1,pts2)\n",
    " \n",
    "dst = cv.warpPerspective(img,M,(300,300))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673746a-e908-4335-a115-9dc086cd68c5",
   "metadata": {},
   "source": [
    "## 2-9. Image Thresholding\n",
    "### 2-9-1. Simple Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024f53a-de26-4c90-bd7f-ba6bf00913a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('gradient.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "ret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "ret,thresh2 = cv.threshold(img,127,255,cv.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv.threshold(img,127,255,cv.THRESH_TRUNC)\n",
    "ret,thresh4 = cv.threshold(img,127,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img,127,255,cv.THRESH_TOZERO_INV)\n",
    " \n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    " \n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray',vmin=0,vmax=255)\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fc168-501d-4dee-b5e7-18ec0777ce72",
   "metadata": {},
   "source": [
    "### 2-9-2. Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a84ab-1916-4a06-a27d-3a1729e057e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('sudoku.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "img = cv.medianBlur(img,5)\n",
    " \n",
    "ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    " \n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    " \n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f8da5-a661-451a-8482-64f932023035",
   "metadata": {},
   "source": [
    "### 2-9-3. Otsu's Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25180e97-581b-439d-9d45-ae40c81b9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('noisy2.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# global thresholding\n",
    "ret1,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    " \n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    " \n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv.GaussianBlur(img,(5,5),0)\n",
    "ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    " \n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    " \n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a06d88-e57d-4e92-95f5-9c47a1c9eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('noisy2.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "blur = cv.GaussianBlur(img,(5,5),0)\n",
    " \n",
    "# find normalized_histogram, and its cumulative distribution function\n",
    "hist = cv.calcHist([blur],[0],None,[256],[0,256])\n",
    "hist_norm = hist.ravel()/hist.sum()\n",
    "Q = hist_norm.cumsum()\n",
    " \n",
    "bins = np.arange(256)\n",
    " \n",
    "fn_min = np.inf\n",
    "thresh = -1\n",
    " \n",
    "for i in range(1,256):\n",
    "    p1,p2 = np.hsplit(hist_norm,[i]) # probabilities\n",
    "    q1,q2 = Q[i],Q[255]-Q[i] # cum sum of classes\n",
    "    if q1 < 1.e-6 or q2 < 1.e-6:\n",
    "        continue\n",
    "    b1,b2 = np.hsplit(bins,[i]) # weights\n",
    " \n",
    "    # finding means and variances\n",
    "    m1,m2 = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2\n",
    "    v1,v2 = np.sum(((b1-m1)**2)*p1)/q1,np.sum(((b2-m2)**2)*p2)/q2\n",
    " \n",
    "    # calculates the minimization function\n",
    "    fn = v1*q1 + v2*q2\n",
    "    if fn < fn_min:\n",
    "        fn_min = fn\n",
    "        thresh = i\n",
    " \n",
    "# find otsu's threshold value with OpenCV function\n",
    "ret, otsu = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "print( \"{} {}\".format(thresh,ret) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7678e-d877-4fe0-8ce6-fbe5041a3d2b",
   "metadata": {},
   "source": [
    "## 2-10. Image Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc0ca9-062b-42e1-966a-6ce693a97cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('opencv_logo.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "dst = cv.filter2D(img,-1,kernel)\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63efc33-4333-4dc6-ae02-24b0849f3e3c",
   "metadata": {},
   "source": [
    "## 2-11. Image Smoothing\n",
    "### 2-11-1. Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afcce9-3557-4723-9f50-e95e77676d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('opencv-logo-white.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "blur = cv.blur(img,(5,5))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643902b7-c215-42ae-badd-c752cbf6d919",
   "metadata": {},
   "source": [
    "### 2-11-2. Gaussian Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6cd8c-4350-4d6d-8b9f-e4b7bc986960",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.GaussianBlur(img,(5,5),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a287f0f-b92e-4ef1-8c28-6e254a67e83e",
   "metadata": {},
   "source": [
    "### 2-11-3. Median Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17aadf8-b5f4-48f0-8228-3554b490322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cv.medianBlur(img,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31839fb0-528d-41e8-9f51-a48681914b70",
   "metadata": {},
   "source": [
    "### 2-11-4. Bilateral Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b24174-cc24-4650-9df1-ea5d78ebf071",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.bilateralFilter(img,9,75,75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5680cb0-34a7-4745-9c94-9beb9e7c3795",
   "metadata": {},
   "source": [
    "## 2-12. Morphological Transformations\n",
    "### 2-12-1. Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd620e38-bca9-4934-af28-308cb6e8bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "img = cv.imread('j.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv.erode(img,kernel,iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17226b6-7ccc-43ec-b2d4-3481b25431c1",
   "metadata": {},
   "source": [
    "### 2-12-2. Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6385c-29da-4173-9820-62bb9e773f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv.dilate(img,kernel,iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1051de-0283-49b8-b84c-2d1cdd35e269",
   "metadata": {},
   "source": [
    "### 2-12-3. Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97591380-73fb-4ac4-8e40-f3d78ca06c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c8166-a1d3-4740-9d43-41ce023bbdcc",
   "metadata": {},
   "source": [
    "### 2-12-4. Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14e969-9f91-4595-83f0-ac7a02d4a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5444fb-cbc7-4cb8-a1fc-18d519748580",
   "metadata": {},
   "source": [
    "### 2-12-5. Morphological Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5dece4-354c-4cd8-8078-4fc66a0a1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba298c-5f3e-4a3b-b7d4-f814916bf5dc",
   "metadata": {},
   "source": [
    "### 2-12-6. Top Hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b51921-2cbf-4436-a697-4652af7c4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "tophat = cv.morphologyEx(img, cv.MORPH_TOPHAT, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9a9de-02f2-4823-a376-a3104b278939",
   "metadata": {},
   "source": [
    "### 2-12-7. Black Hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a2f4c-a241-45e5-bd01-10d03d175981",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackhat = cv.morphologyEx(img, cv.MORPH_BLACKHAT, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d10bc9-af6b-4f65-a04e-8dec98af0253",
   "metadata": {},
   "source": [
    "### 2-12-8. Structuring Elements\n",
    "1. `cv2.getStructuringElement(shape, ksize, anchor=Point(-1,-1))`: Returns a structuring element of the specified size and shape for morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade981fc-0cf0-4d33-a091-e8564d15b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectangular Kernel\n",
    "cv.getStructuringElement(cv.MORPH_RECT,(5,5))\n",
    "array([[1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1]], dtype=uint8)\n",
    " \n",
    "# Elliptical Kernel\n",
    "cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "array([[0, 0, 1, 0, 0],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [0, 0, 1, 0, 0]], dtype=uint8)\n",
    " \n",
    "# Cross-shaped Kernel\n",
    "cv.getStructuringElement(cv.MORPH_CROSS,(5,5))\n",
    "array([[0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [0, 0, 1, 0, 0],\n",
    "       [0, 0, 1, 0, 0]], dtype=uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fba59-74c8-45b5-bcd4-ed9a5eea9c69",
   "metadata": {},
   "source": [
    "## 2-13. Image Gradients\n",
    "OpenCV provides three types of gradient filters or High-pass filters.\n",
    "1. `cv2.Sobel(src, dst, ddepth, dx, dy, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)`\n",
    "2. `cv2.Scharr(src, dst, ddepth, dx, dy, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)`\n",
    "3. `cv2.Laplacian(src, dst, ddepth, ksize=1, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c781a-8c25-4087-b4e9-1fef472a70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('dave.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "laplacian = cv.Laplacian(img,ddepth=cv.CV_64F)\n",
    "sobelx = cv.Sobel(img,ddepth=cv.CV_64F,dx=1,dy=0,ksize=5)\n",
    "sobely = cv.Sobel(img,ddepth=cv.CV_64F,dx=0,dy=1,ksize=5)\n",
    " \n",
    "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
    "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460809b5-d008-4f75-9927-a54564467e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('box.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# Output dtype = cv.CV_8U\n",
    "sobelx8u = cv.Sobel(img,cv.CV_8U,1,0,ksize=5)\n",
    " \n",
    "# Output dtype = cv.CV_64F. Then take its absolute and convert to cv.CV_8U\n",
    "sobelx64f = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)\n",
    "abs_sobel64f = np.absolute(sobelx64f)\n",
    "sobel_8u = np.uint8(abs_sobel64f)\n",
    " \n",
    "plt.subplot(1,3,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,2),plt.imshow(sobelx8u,cmap = 'gray')\n",
    "plt.title('Sobel CV_8U'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,3,3),plt.imshow(sobel_8u,cmap = 'gray')\n",
    "plt.title('Sobel abs(CV_64F)'), plt.xticks([]), plt.yticks([])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3062a51-979a-43df-8db0-2d9ecfce4b81",
   "metadata": {},
   "source": [
    "## 2-14. Canny Edge Detection\n",
    "1. `cv2.Canny(image, threshold1, threshold2, edges, apertureSize=3, L2gradient=False)`: Finds edges in the input image and marks them in the output map edges using the Canny algorithm. The smaller value between `threshold1` and `threshold2` is used for edge linking; the larger one is used to find initial segments of strong edges.\n",
    "2. `cv2.Canny(dx, dy, threshold1, threshold2, edges, L2gradient=False)`: Overloaded member function. `dx` & `dy` indicates $16$-bit $x$ & $y$ derivative of input image respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df891749-e78f-45e4-b5f2-4ebb57c2bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "edges = cv.Canny(img,100,200)\n",
    " \n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ee77d-ff10-4b03-af58-5d51bcd145e4",
   "metadata": {},
   "source": [
    "## 2-15. Image Pyramids\n",
    "1. `cv.pyrUp()`\n",
    "2. `cv.pyrDown()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec71fd7-4ceb-4199-b150-6aa4fbbd3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('messi5.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "lower_reso = cv.pyrDown(higher_reso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c9953-208d-444c-975d-bcb7dce399e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_reso2 = cv.pyrUp(lower_reso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209f5a0-8fe3-4d6e-9b7f-f62f1c2fe866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image blending using pyramids\n",
    "import cv2 as cv\n",
    "import numpy as np,sys\n",
    " \n",
    "A = cv.imread('apple.jpg')\n",
    "B = cv.imread('orange.jpg')\n",
    "assert A is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert B is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# generate Gaussian pyramid for A\n",
    "G = A.copy()\n",
    "gpA = [G]\n",
    "for i in range(6):\n",
    "    G = cv.pyrDown(G)\n",
    "    gpA.append(G)\n",
    " \n",
    "# generate Gaussian pyramid for B\n",
    "G = B.copy()\n",
    "gpB = [G]\n",
    "for i in range(6):\n",
    "    G = cv.pyrDown(G)\n",
    "    gpB.append(G)\n",
    " \n",
    "# generate Laplacian Pyramid for A\n",
    "lpA = [gpA[5]]\n",
    "for i in range(5,0,-1):\n",
    "    GE = cv.pyrUp(gpA[i])\n",
    "    L = cv.subtract(gpA[i-1],GE)\n",
    "    lpA.append(L)\n",
    " \n",
    "# generate Laplacian Pyramid for B\n",
    "lpB = [gpB[5]]\n",
    "for i in range(5,0,-1):\n",
    "    GE = cv.pyrUp(gpB[i])\n",
    "    L = cv.subtract(gpB[i-1],GE)\n",
    "    lpB.append(L)\n",
    " \n",
    "# Now add left and right halves of images in each level\n",
    "LS = []\n",
    "for la,lb in zip(lpA,lpB):\n",
    "    rows,cols,dpt = la.shape\n",
    "    ls = np.hstack((la[:,0:cols//2], lb[:,cols//2:]))\n",
    "    LS.append(ls)\n",
    " \n",
    "# now reconstruct\n",
    "ls_ = LS[0]\n",
    "for i in range(1,6):\n",
    "    ls_ = cv.pyrUp(ls_)\n",
    "    ls_ = cv.add(ls_, LS[i])\n",
    " \n",
    "# image with direct connecting each half\n",
    "real = np.hstack((A[:,:cols//2],B[:,cols//2:]))\n",
    " \n",
    "cv.imwrite('Pyramid_blending2.jpg',ls_)\n",
    "cv.imwrite('Direct_blending.jpg',real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8fc8a-bb4a-4a09-85d5-dbe6123813fc",
   "metadata": {},
   "source": [
    "## 2-16. Contours\n",
    "### 2-16-1. Find & Draw Contours\n",
    "1. `cv2.findContours()`\n",
    "   - `mode`: Contour retrieval mode.\n",
    "       - `cv2.RETR_LIST`\n",
    "       - `cv2.RETR_TREE`\n",
    "       - `cv2.RETR_CCOMP`\n",
    "       - `cv2.RETR_EXTERNAL`\n",
    "3. `cv2.drawContours()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb85d9-d009-465a-b663-4a0a2049a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "im = cv.imread('test.jpg')\n",
    "assert im is not None, \"file could not be read, check with os.path.exists()\"\n",
    "imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv.threshold(imgray, 127, 255, 0)\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9095d8-2a55-4c95-9885-f0a050b25142",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.drawContours(img, contours, -1, (0,255,0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ff538-e000-4dba-9309-7507462aad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.drawContours(img, contours, 3, (0,255,0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8effe6-df26-407a-b67b-c7bae170fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = contours[4]\n",
    "cv.drawContours(img, [cnt], 0, (0,255,0), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f7f36b-7e27-4535-bf38-e7fc134c9deb",
   "metadata": {},
   "source": [
    "### 2-16-2. Contour Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab9591-2b10-41a3-8fdd-552eb0dde8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('star.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "ret,thresh = cv.threshold(img,127,255,0)\n",
    "contours,hierarchy = cv.findContours(thresh, 1, 2)\n",
    " \n",
    "cnt = contours[0]\n",
    "M = cv.moments(cnt)\n",
    "print( M )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de96fe9-9b22-4565-8cdb-ee4ca907e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = int(M['m10']/M['m00'])\n",
    "cy = int(M['m01']/M['m00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03dba42-49bc-42ea-ab95-eb805b0de550",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = cv.contourArea(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd97ae5-62f7-44f4-bb62-54f2bfafc9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "perimeter = cv.arcLength(cnt,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe6209-a872-427b-b09d-6282ef0645d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1*cv.arcLength(cnt,True)\n",
    "approx = cv.approxPolyDP(cnt,epsilon,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeec0d4-9bcd-4e6e-94c4-4fa6622ef0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = cv.convexHull(points[, hull[, clockwise[, returnPoints]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef462d4-d852-45db-bc6f-408ab9ac424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = cv.convexHull(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c705f6-90c2-4941-b86b-6e6aa444ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = cv.isContourConvex(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68712d7-6487-429d-8011-586b6775fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = cv.boundingRect(cnt)\n",
    "cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79665dad-4226-4761-9c27-fb1f60995d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = cv.minAreaRect(cnt)\n",
    "box = cv.boxPoints(rect)\n",
    "box = np.int0(box)\n",
    "cv.drawContours(img,[box],0,(0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097f5f4-388e-445a-acdf-4768d60bbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),radius = cv.minEnclosingCircle(cnt)\n",
    "center = (int(x),int(y))\n",
    "radius = int(radius)\n",
    "cv.circle(img,center,radius,(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d99728-09db-40fa-ab55-0b96a0f3c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipse = cv.fitEllipse(cnt)\n",
    "cv.ellipse(img,ellipse,(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd2e94a-d6b6-4d9a-a6bb-ce7cfb06683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols = img.shape[:2]\n",
    "[vx,vy,x,y] = cv.fitLine(cnt, cv.DIST_L2,0,0.01,0.01)\n",
    "lefty = int((-x*vy/vx) + y)\n",
    "righty = int(((cols-x)*vy/vx)+y)\n",
    "cv.line(img,(cols-1,righty),(0,lefty),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b252ae-d116-401f-a26f-1b0cc1b7e9e6",
   "metadata": {},
   "source": [
    "### 2-16-3. Contour Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e1901-31e5-439a-b5df-f1a10475a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = cv.boundingRect(cnt)\n",
    "aspect_ratio = float(w)/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1981d5-ca60-4565-8b57-15504fe8c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = cv.contourArea(cnt)\n",
    "x,y,w,h = cv.boundingRect(cnt)\n",
    "rect_area = w*h\n",
    "extent = float(area)/rect_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5ffe1-5ab9-4b71-8ebf-22595930af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = cv.contourArea(cnt)\n",
    "hull = cv.convexHull(cnt)\n",
    "hull_area = cv.contourArea(hull)\n",
    "solidity = float(area)/hull_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45fdb6-4538-4df9-9575-1f6f211a34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = cv.contourArea(cnt)\n",
    "equi_diameter = np.sqrt(4*area/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1268f2-b63b-4a24-aa6d-6d6e86ec7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),(MA,ma),angle = cv.fitEllipse(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adad7fc-fbc8-4dc9-861c-0b94a2f3fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(imgray.shape,np.uint8)\n",
    "cv.drawContours(mask,[cnt],0,255,-1)\n",
    "pixelpoints = np.transpose(np.nonzero(mask))\n",
    "#pixelpoints = cv.findNonZero(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dfa094-e374-4b1f-ab7b-35d8536e8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val, max_val, min_loc, max_loc = cv.minMaxLoc(imgray,mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a2ca9-ca29-4843-8a11-6c02be1920ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = cv.mean(im,mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f3e49-6608-457c-aac3-fcb253e7f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftmost = tuple(cnt[cnt[:,:,0].argmin()][0])\n",
    "rightmost = tuple(cnt[cnt[:,:,0].argmax()][0])\n",
    "topmost = tuple(cnt[cnt[:,:,1].argmin()][0])\n",
    "bottommost = tuple(cnt[cnt[:,:,1].argmax()][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ec295-40f1-4c1d-84b5-eb2b50d814a7",
   "metadata": {},
   "source": [
    "### 2-16-4. Convexity Defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a7679-08c9-4679-a612-3809a05c745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = cv.convexHull(cnt,returnPoints = False)\n",
    "defects = cv.convexityDefects(cnt,hull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63abaca-545c-4198-9340-30bc89a6de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "img = cv.imread('star.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "img_gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv.threshold(img_gray, 127, 255,0)\n",
    "contours,hierarchy = cv.findContours(thresh,2,1)\n",
    "cnt = contours[0]\n",
    " \n",
    "hull = cv.convexHull(cnt,returnPoints = False)\n",
    "defects = cv.convexityDefects(cnt,hull)\n",
    " \n",
    "for i in range(defects.shape[0]):\n",
    "    s,e,f,d = defects[i,0]\n",
    "    start = tuple(cnt[s][0])\n",
    "    end = tuple(cnt[e][0])\n",
    "    far = tuple(cnt[f][0])\n",
    "    cv.line(img,start,end,[0,255,0],2)\n",
    "    cv.circle(img,far,5,[0,0,255],-1)\n",
    " \n",
    "cv.imshow('img',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a5e36-e0b7-4bdc-b516-721e85c4c576",
   "metadata": {},
   "source": [
    "### 2-16-5. Point Polygon Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e4450-5296-4839-b5d2-b63862fcfca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = cv.pointPolygonTest(cnt,(50,50),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305308e0-5a74-4035-b2fd-b9b7a5d1aabd",
   "metadata": {},
   "source": [
    "### 2-16-6. Shape Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c74f65-7a79-4d6d-861c-5155034545d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "img1 = cv.imread('star.jpg', cv.IMREAD_GRAYSCALE)\n",
    "img2 = cv.imread('star2.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert img2 is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "ret, thresh = cv.threshold(img1, 127, 255,0)\n",
    "ret, thresh2 = cv.threshold(img2, 127, 255,0)\n",
    "contours,hierarchy = cv.findContours(thresh,2,1)\n",
    "cnt1 = contours[0]\n",
    "contours,hierarchy = cv.findContours(thresh2,2,1)\n",
    "cnt2 = contours[0]\n",
    " \n",
    "ret = cv.matchShapes(cnt1,cnt2,1,0.0)\n",
    "print( ret )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f91c1-0dc0-415a-a118-716d525011aa",
   "metadata": {},
   "source": [
    "## 2-17. Histograms\n",
    "### 2-17-1. Histogram Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d4394-62a6-47b6-b9e5-c42d8bd10c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV\n",
    "img = cv.imread('home.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "hist = cv.calcHist([img],[0],None,[256],[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b80f4-226f-4914-9acf-0fdb8430868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "hist,bins = np.histogram(img.ravel(),256,[0,256])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5947d2-7d71-402a-bd7d-b0de8956f2d9",
   "metadata": {},
   "source": [
    "### 2-17-2. Plot Histograms with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292db3a-3242-47bb-94de-f800f9003aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('home.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "plt.hist(img.ravel(),256,[0,256]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b3192-8a14-40d9-ac3b-56d23437730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('home.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c2bc61-8ee1-478a-bff8-0b7041e673a6",
   "metadata": {},
   "source": [
    "### 2-17-3. Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170e845-d80c-485a-bdcf-c21596392698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask\n",
    "img = cv.imread('home.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# create a mask\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "mask[100:300, 100:400] = 255\n",
    "masked_img = cv.bitwise_and(img,img,mask = mask)\n",
    " \n",
    "# Calculate histogram with mask and without mask\n",
    "# Check third argument for mask\n",
    "hist_full = cv.calcHist([img],[0],None,[256],[0,256])\n",
    "hist_mask = cv.calcHist([img],[0],mask,[256],[0,256])\n",
    " \n",
    "plt.subplot(221), plt.imshow(img, 'gray')\n",
    "plt.subplot(222), plt.imshow(mask,'gray')\n",
    "plt.subplot(223), plt.imshow(masked_img, 'gray')\n",
    "plt.subplot(224), plt.plot(hist_full), plt.plot(hist_mask)\n",
    "plt.xlim([0,256])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdf61f-1117-42b0-9b67-b7c581dd0362",
   "metadata": {},
   "source": [
    "### 2-17-4. Histogram Equalization\n",
    "**CLAHE (Contrast Limited Adaptive Histogram Equalization)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275a1f7-e610-4dab-ab39-f4086a63708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('wiki.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "hist,bins = np.histogram(img.flatten(),256,[0,256])\n",
    " \n",
    "cdf = hist.cumsum()\n",
    "cdf_normalized = cdf * float(hist.max()) / cdf.max()\n",
    " \n",
    "plt.plot(cdf_normalized, color = 'b')\n",
    "plt.hist(img.flatten(),256,[0,256], color = 'r')\n",
    "plt.xlim([0,256])\n",
    "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e557e37-d543-470b-b9ec-14d651545c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_m = np.ma.masked_equal(cdf,0)\n",
    "cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "cdf = np.ma.filled(cdf_m,0).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd00ab5-6a35-4f13-b614-554cbb36510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cdf[img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7136d-ecc5-4c78-9048-ef78ec726ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('wiki.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "equ = cv.equalizeHist(img)\n",
    "res = np.hstack((img,equ)) #stacking images side-by-side\n",
    "cv.imwrite('res.png',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89c374-df80-4c95-8154-6ebe55e2476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('tsukuba_l.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cl1 = clahe.apply(img)\n",
    " \n",
    "cv.imwrite('clahe_2.jpg',cl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9bd51-430a-4894-96cb-50493dec0ee6",
   "metadata": {},
   "source": [
    "### 2-17-5. 2D Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddaf1d-2def-41a9-b3c8-6780141da29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('home.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)\n",
    " \n",
    "hist = cv.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e1de8e-0a9c-422f-ace0-dc6e1bcf132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('home.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)\n",
    " \n",
    "hist, xbins, ybins = np.histogram2d(h.ravel(),s.ravel(),[180,256],[[0,180],[0,256]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1e60c-4216-4350-9bcc-fb84f3533b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('home.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "hsv = cv.cvtColor(img,cv.COLOR_BGR2HSV)\n",
    "hist = cv.calcHist( [hsv], [0, 1], None, [180, 256], [0, 180, 0, 256] )\n",
    " \n",
    "plt.imshow(hist,interpolation = 'nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21db69a-bb5e-498b-a2ae-8dc645277eda",
   "metadata": {},
   "source": [
    "### 2-17-6. Histogram Backprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52fb665-d691-4546-9e63-3c3d54d12202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "import cv2 as cvfrom matplotlib import pyplot as plt\n",
    " \n",
    "#roi is the object or region of object we need to find\n",
    "roi = cv.imread('rose_red.png')\n",
    "assert roi is not None, \"file could not be read, check with os.path.exists()\"\n",
    "hsv = cv.cvtColor(roi,cv.COLOR_BGR2HSV)\n",
    " \n",
    "#target is the image we search in\n",
    "target = cv.imread('rose.png')\n",
    "assert target is not None, \"file could not be read, check with os.path.exists()\"\n",
    "hsvt = cv.cvtColor(target,cv.COLOR_BGR2HSV)\n",
    " \n",
    "# Find the histograms using calcHist. Can be done with np.histogram2d also\n",
    "M = cv.calcHist([hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )\n",
    "I = cv.calcHist([hsvt],[0, 1], None, [180, 256], [0, 180, 0, 256] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ee6b8-aeb2-4c9f-821c-dcf48ff03377",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,s,v = cv.split(hsvt)\n",
    "B = R[h.ravel(),s.ravel()]\n",
    "B = np.minimum(B,1)\n",
    "B = B.reshape(hsvt.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7911aa8-6e4b-4ef8-8573-10d9f24c014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "cv.filter2D(B,-1,disc,B)\n",
    "B = np.uint8(B)\n",
    "cv.normalize(B,B,0,255,cv.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f96725-e560-4e6d-a688-4bbbb6d63f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh = cv.threshold(B,50,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2e97d-67ea-4f62-83bc-3e70de29c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "roi = cv.imread('rose_red.png')\n",
    "assert roi is not None, \"file could not be read, check with os.path.exists()\"\n",
    "hsv = cv.cvtColor(roi,cv.COLOR_BGR2HSV)\n",
    " \n",
    "target = cv.imread('rose.png')\n",
    "assert target is not None, \"file could not be read, check with os.path.exists()\"\n",
    "hsvt = cv.cvtColor(target,cv.COLOR_BGR2HSV)\n",
    " \n",
    "# calculating object histogram\n",
    "roihist = cv.calcHist([hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )\n",
    " \n",
    "# normalize histogram and apply backprojection\n",
    "cv.normalize(roihist,roihist,0,255,cv.NORM_MINMAX)\n",
    "dst = cv.calcBackProject([hsvt],[0,1],roihist,[0,180,0,256],1)\n",
    " \n",
    "# Now convolute with circular disc\n",
    "disc = cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "cv.filter2D(dst,-1,disc,dst)\n",
    " \n",
    "# threshold and binary AND\n",
    "ret,thresh = cv.threshold(dst,50,255,0)\n",
    "thresh = cv.merge((thresh,thresh,thresh))\n",
    "res = cv.bitwise_and(target,thresh)\n",
    " \n",
    "res = np.vstack((target,thresh,res))\n",
    "cv.imwrite('res.jpg',res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce081757-0c72-45cd-a941-85ab393aa601",
   "metadata": {},
   "source": [
    "## 2-18. Image Transforms\n",
    "- [Image Transforms](https://www.mathworks.com/help/images/image-transforms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc1edb1-dd6f-46c8-9bc2-3cedf3784973",
   "metadata": {},
   "source": [
    "### 2-18-1. Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821c6eb-bbe8-413d-b911-2e85e83df782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "f = np.fft.fft2(img)\n",
    "fshift = np.fft.fftshift(f)\n",
    "magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd35f4-cb53-4591-af8a-3d6af2191018",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = img.shape\n",
    "crow, ccol = rows//2, cols//2\n",
    "fshift[crow-30:crow+31, ccol-30:ccol+31] = 0\n",
    "f_ishift = np.fft.ifftshift(fshift)\n",
    "img_back = np.fft.ifft2(f_ishift)\n",
    "img_back = np.real(img_back)\n",
    " \n",
    "plt.subplot(131),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132),plt.imshow(img_back, cmap = 'gray')\n",
    "plt.title('Image after HPF'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(img_back)\n",
    "plt.title('Result in JET'), plt.xticks([]), plt.yticks([])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c1334-a953-4db2-9c1b-29f7a8882aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "dft = cv.dft(np.float32(img),flags = cv.DFT_COMPLEX_OUTPUT)\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    " \n",
    "magnitude_spectrum = 20*np.log(cv.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0430f4-6e18-494c-8000-96e2c152cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = img.shape\n",
    "crow, ccol = rows//2, cols//2\n",
    " \n",
    "# create a mask first, center square is 1, remaining all zeros\n",
    "mask = np.zeros((rows,cols,2),np.uint8)\n",
    "mask[crow-30:crow+30, ccol-30:ccol+30] = 1\n",
    " \n",
    "# apply mask and inverse DFT\n",
    "fshift = dft_shift*mask\n",
    "f_ishift = np.fft.ifftshift(fshift)\n",
    "img_back = cv.idft(f_ishift)\n",
    "img_back = cv.magnitude(img_back[:,:,0],img_back[:,:,1])\n",
    " \n",
    "plt.subplot(121),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(img_back, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66961101-04aa-44c2-8bcf-8cb918ae494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Optimization of DFT\n",
    "In [15]: img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "In [16]: assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "In [17]: rows,cols = img.shape\n",
    "In [18]: print(\"{} {}\".format(rows,cols))\n",
    "342 548\n",
    " \n",
    "In [19]: nrows = cv.getOptimalDFTSize(rows)\n",
    "In [20]: ncols = cv.getOptimalDFTSize(cols)\n",
    "In [21]: print(\"{} {}\".format(nrows,ncols))\n",
    "360 576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa033b4d-51fd-47f2-8d76-b682e775f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimg = np.zeros((nrows,ncols))\n",
    "nimg[:rows,:cols] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7c175-f735-4df3-8c26-3b9b57664a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "right = ncols - cols\n",
    "bottom = nrows - rows\n",
    "bordertype = cv.BORDER_CONSTANT #just to avoid line breakup in PDF file\n",
    "nimg = cv.copyMakeBorder(img,0,bottom,0,right,bordertype, value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b870d2e-c28d-4482-b89a-5289da54f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [22]: %timeit fft1 = np.fft.fft2(img)\n",
    "10 loops, best of 3: 40.9 ms per loop\n",
    "In [23]: %timeit fft2 = np.fft.fft2(img,[nrows,ncols])\n",
    "100 loops, best of 3: 10.4 ms per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba2004-794b-445c-b0af-0a5451e86fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "In [24]: %timeit dft1= cv.dft(np.float32(img),flags=cv.DFT_COMPLEX_OUTPUT)\n",
    "100 loops, best of 3: 13.5 ms per loop\n",
    "In [27]: %timeit dft2= cv.dft(np.float32(nimg),flags=cv.DFT_COMPLEX_OUTPUT)\n",
    "100 loops, best of 3: 3.11 ms per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596e58f-b856-46b8-9f0a-018a27fe8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why Laplacian is a High Pass Filter?\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "# simple averaging filter without scaling parameter\n",
    "mean_filter = np.ones((3,3))\n",
    " \n",
    "# creating a gaussian filter\n",
    "x = cv.getGaussianKernel(5,10)\n",
    "gaussian = x*x.T\n",
    " \n",
    "# different edge detecting filters\n",
    "# scharr in x-direction\n",
    "scharr = np.array([[-3, 0, 3],\n",
    "                   [-10,0,10],\n",
    "                   [-3, 0, 3]])\n",
    "# sobel in x direction\n",
    "sobel_x= np.array([[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]])\n",
    "# sobel in y direction\n",
    "sobel_y= np.array([[-1,-2,-1],\n",
    "                   [0, 0, 0],\n",
    "                   [1, 2, 1]])\n",
    "# laplacian\n",
    "laplacian=np.array([[0, 1, 0],\n",
    "                    [1,-4, 1],\n",
    "                    [0, 1, 0]])\n",
    " \n",
    "filters = [mean_filter, gaussian, laplacian, sobel_x, sobel_y, scharr]\n",
    "filter_name = ['mean_filter', 'gaussian','laplacian', 'sobel_x', \\\n",
    "                'sobel_y', 'scharr_x']\n",
    "fft_filters = [np.fft.fft2(x) for x in filters]\n",
    "fft_shift = [np.fft.fftshift(y) for y in fft_filters]\n",
    "mag_spectrum = [np.log(np.abs(z)+1) for z in fft_shift]\n",
    " \n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(mag_spectrum[i],cmap = 'gray')\n",
    "    plt.title(filter_name[i]), plt.xticks([]), plt.yticks([])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056ee98-e99f-4a63-8ce7-4dab9117149e",
   "metadata": {},
   "source": [
    "### 2-18-2. Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f2a12-ede1-42b6-804a-0c6669668c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hough line transform\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "img = cv.imread(cv.samples.findFile('sudoku.png'))\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "edges = cv.Canny(gray,50,150,apertureSize = 3)\n",
    " \n",
    "lines = cv.HoughLines(edges,1,np.pi/180,200)\n",
    "for line in lines:\n",
    "    rho,theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    " \n",
    "    cv.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    " \n",
    "cv.imwrite('houghlines3.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a134e-6c2e-4da4-8e55-08a9a676f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "img = cv.imread(cv.samples.findFile('sudoku.png'))\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "edges = cv.Canny(gray,50,150,apertureSize = 3)\n",
    "lines = cv.HoughLinesP(edges,1,np.pi/180,100,minLineLength=100,maxLineGap=10)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    " \n",
    "cv.imwrite('houghlines5.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf4f78-939c-4f1d-b8d7-fd5a81386811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hough circle transform\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('opencv-logo-white.png', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "img = cv.medianBlur(img,5)\n",
    "cimg = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n",
    " \n",
    "circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,20,\n",
    "                            param1=50,param2=30,minRadius=0,maxRadius=0)\n",
    " \n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv.circle(cimg,(i[0],i[1]),2,(0,0,255),3)\n",
    " \n",
    "cv.imshow('detected circles',cimg)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3479e-c131-4b69-909c-7601c80c0042",
   "metadata": {},
   "source": [
    "## 2-19. Template Matching\n",
    "1. `cv2.matchTemplate()`\n",
    "2. `cv2.minMaxLoc()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12c0e1-2af8-4e09-a126-b109c46266ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('messi5.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "img2 = img.copy()\n",
    "template = cv.imread('template.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert template is not None, \"file could not be read, check with os.path.exists()\"\n",
    "w, h = template.shape[::-1]\n",
    " \n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['TM_CCOEFF', 'TM_CCOEFF_NORMED', 'TM_CCORR',\n",
    "            'TM_CCORR_NORMED', 'TM_SQDIFF', 'TM_SQDIFF_NORMED']\n",
    " \n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = getattr(cv, meth)\n",
    " \n",
    "    # Apply template Matching\n",
    "    res = cv.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    " \n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    " \n",
    "    cv.rectangle(img,top_left, bottom_right, 255, 2)\n",
    " \n",
    "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007be45-fce5-4637-b9f9-3464d490f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img_rgb = cv.imread('mario.png')\n",
    "assert img_rgb is not None, \"file could not be read, check with os.path.exists()\"\n",
    "img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
    "template = cv.imread('mario_coin.png', cv.IMREAD_GRAYSCALE)\n",
    "assert template is not None, \"file could not be read, check with os.path.exists()\"\n",
    "w, h = template.shape[::-1]\n",
    " \n",
    "res = cv.matchTemplate(img_gray,template,cv.TM_CCOEFF_NORMED)\n",
    "threshold = 0.8\n",
    "loc = np.where( res >= threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
    " \n",
    "cv.imwrite('res.png',img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d53c1-0088-4aae-9eb8-337929a1920a",
   "metadata": {},
   "source": [
    "## 2-20. Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9eeaef-bc2c-49e5-9f29-540c5f0f57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('coins.png')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1aaaa6-4bec-4c8b-995d-cb6ac7641e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    " \n",
    "# sure background area\n",
    "sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    " \n",
    "# Finding sure foreground area\n",
    "dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "ret, sure_fg = cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    " \n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(sure_bg,sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992ed15-a140-4fe0-bae7-7f01495e14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker labelling\n",
    "ret, markers = cv.connectedComponents(sure_fg)\n",
    " \n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    " \n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ddd3d-ccc1-4306-b89a-5de99c1c5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = cv.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0081ac-ecad-4c1d-a165-d2240fc92fa7",
   "metadata": {},
   "source": [
    "## 2-21. Interactive Foreground Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56620055-9166-4894-95e4-d93ec0e68b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "img = cv.imread('messi5.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    " \n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    " \n",
    "rect = (50,50,450,290)\n",
    "cv.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)\n",
    " \n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    " \n",
    "plt.imshow(img),plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0f844-dda8-4589-ab55-45ab43829301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newmask is the mask image I manually labelled\n",
    "newmask = cv.imread('newmask.png', cv.IMREAD_GRAYSCALE)\n",
    "assert newmask is not None, \"file could not be read, check with os.path.exists()\"\n",
    " \n",
    "# wherever it is marked white (sure foreground), change mask=1\n",
    "# wherever it is marked black (sure background), change mask=0\n",
    "mask[newmask == 0] = 0\n",
    "mask[newmask == 255] = 1\n",
    " \n",
    "mask, bgdModel, fgdModel = cv.grabCut(img,mask,None,bgdModel,fgdModel,5,cv.GC_INIT_WITH_MASK)\n",
    " \n",
    "mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask[:,:,np.newaxis]\n",
    "plt.imshow(img),plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab84f84-1010-459a-a3be-e472408921b1",
   "metadata": {},
   "source": [
    "# 3. Feature Detection & Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332affce-2a64-47cc-be2c-3856242f4aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07f6a284-d962-4e39-a4d3-5d39a91f34c3",
   "metadata": {},
   "source": [
    "# 4. Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f425e55d-08fc-448e-b033-dce74143cce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f2b3a68-631f-45bd-a4b1-9740c5b76ffc",
   "metadata": {},
   "source": [
    "# 5. Camera Calibration & 3D Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc1d63a-6103-4ef4-af23-ae9459bd1e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6a8b5fe-2887-4704-98f8-6fd8b2816db7",
   "metadata": {},
   "source": [
    "# 6. Computational Photography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c76d6-ab58-48ea-8015-5050bae1938c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c53110d-e24e-4937-aa99-16ee5c33b9a1",
   "metadata": {},
   "source": [
    "# 7. Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b22793-7cb6-408b-828c-19f9ed35b99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
